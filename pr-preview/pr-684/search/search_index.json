{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#metriq-gym","title":"metriq-gym","text":"<p>metriq-gym is a Python framework for implementing and running standard quantum benchmarks on different quantum devices by different providers.</p> <ul> <li>Open \u2013 Open-source since its inception and fully developed in public.</li> <li>Transparent \u2013 All benchmark parameters are defined in a schema file and the benchmark code is reviewable by the community.</li> <li>Cross-platform \u2013 Supports running benchmarks on multiple quantum hardware providers (integration powered by qBraid-SDK)</li> <li>User-friendly \u2013 Provides a simple command-line interface for dispatching, monitoring, and polling benchmark jobs (you can go on with your life while your job waits in the queue).</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Four easy steps to get started with <code>metriq-gym</code>!</p> <ol> <li>Install <code>metriq-gym</code> directly in your Python environment using pip:</li> </ol> <pre><code>pip install metriq-gym\n</code></pre> <ol> <li> <p>Download a benchmark configuration file from the <code>schemas/examples/</code> directory (this example uses the WIT \u2014 Wormhole-inspired teleportation \u2014 benchmark)</p> <pre><code>curl -O https://raw.githubusercontent.com/unitaryfoundation/metriq-gym/refs/heads/main/metriq_gym/schemas/examples/wit.example.json\n</code></pre> </li> <li> <p>Dispatch it to a quantum device or simulator.</p> <p><pre><code>mgym job dispatch wit.example.json -p local -d aer_simulator\n</code></pre> 4. Poll the job to get the results.</p> <pre><code>mgym job poll latest\n</code></pre> </li> </ol> <p>You will see the results of the benchmark printed in your terminal. E.g. <pre><code>{'app_version': '0.6.0',\n 'job_type': 'WIT',\n 'platform': {'device': 'aer_simulator',\n              'device_metadata': {'num_qubits': 31,\n                                  'simulator': True,\n                                  'version': '0.17.2'},\n              'provider': 'local'},\n 'results': {'expectation_value': {'uncertainty': 0.0006673812593654682,\n                                   'value': 0.996337890625},\n             'score': {'uncertainty': 0.0006673812593654682,\n                       'value': 0.996337890625}},\n 'runtime_seconds': 0.009346791077405214,\n 'suite_id': None,\n 'timestamp': '2026-01-16T15:42:18.173736'}\n\nResults:\n  expectation_value: 0.996337890625 \u00b1 0.0006673812593654682\n  score: 0.996337890625 \u00b1 0.0006673812593654682\n</code></pre></p> <p>Explore more examples in the ready-made JSON schemas under <code>metriq_gym/schemas/examples/</code>.</p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Quickstart Guide - Get up and running quickly</li> <li>CLI Reference - Command-line workflows and credential setup</li> <li>Provider Configuration - Setup guides for IBM, IonQ, AWS, Azure, Quantinuum, OriginQ</li> <li>Benchmarks - Available benchmarks and configuration</li> <li>Developer Guide - Contributing to metriq-gym</li> </ul>"},{"location":"#community","title":"Community","text":"<ul> <li>Join the discussion on Discord (<code>#metriq</code> channel)</li> <li>Ask questions or share ideas via GitHub Discussions</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>Start with CONTRIBUTING.md for the workflow checklist, and review the Developer Guide. Issues and pull requests are welcome!</p>"},{"location":"#license","title":"License","text":"<p>metriq-gym is available under the Apache License 2.0.</p>"},{"location":"benchmarks/overview/","title":"Benchmarks","text":"<p>Metriq-Gym provides a comprehensive suite of quantum benchmarks to characterize and compare quantum hardware performance.</p>"},{"location":"benchmarks/overview/#running-benchmarks","title":"Running Benchmarks","text":""},{"location":"benchmarks/overview/#single-benchmark","title":"Single Benchmark","text":"<pre><code>mgym job dispatch metriq_gym/schemas/examples/quantum_volume.example.json \\\n    --provider local --device aer_simulator\n</code></pre>"},{"location":"benchmarks/overview/#poll-for-results","title":"Poll for Results","text":"<pre><code>mgym job poll &lt;JOB_ID&gt;\n</code></pre>"},{"location":"benchmarks/overview/#configuration","title":"Configuration","text":"<p>All benchmarks use JSON configuration files:</p> <ul> <li>Schemas: <code>metriq_gym/schemas/*.schema.json</code> - Define parameters, types, and allowed values</li> <li>Examples: <code>metriq_gym/schemas/examples/*.example.json</code> - Ready-to-run configurations</li> </ul>"},{"location":"benchmarks/overview/#available-benchmarks","title":"Available Benchmarks","text":"Benchmark Description Mirror Circuits Tests state fidelity via forward/reverse Clifford layers EPLG Error per layered gate across qubit chains BSEQ Bell state effective qubits via CHSH violation WIT Wormhole-inspired teleportation protocol LR-QAOA Linear-ramp QAOA for Max-Cut optimization QML Kernel Quantum machine learning kernel accuracy QED-C Benchmarks Application-oriented benchmarks (BV, QFT, etc.)"},{"location":"benchmarks/overview/#metriq_gym.benchmarks.mirror_circuits","title":"<code>mirror_circuits</code>","text":"<p>Mirror Circuits benchmark implementation.</p> Summary <p>Generates randomly parameterized mirror circuits that apply layers of Clifford gates, add a middle Pauli layer, and then revert the forward layers to test how well a device preserves state fidelity across the forward and reverse halves of the circuit.</p> Result interpretation <p>Polling yields MirrorCircuitsResult with:     - success_probability: fraction of runs matching the expected bitstring.     - polarization: rescales success_probability to remove the uniform-random baseline;       higher implies better performance.     - binary_success: boolean indicating whether polarization exceeded 1/e.</p> References <ul> <li>Proctor et al., \"Measuring the capabilities of quantum computers\",   Nature Physics 18, 75-79 (2022).</li> <li>Hines et al., Phys. Rev. Lett. 129, 150502 (2022).</li> </ul>"},{"location":"benchmarks/overview/#metriq_gym.benchmarks.eplg","title":"<code>eplg</code>","text":"<p>EPLG (Error Per Layered Gate) benchmark implementation.</p> Summary <p>Measures layer fidelity across qubit chains using randomized benchmarking techniques. Computes EPLG scores at various chain lengths to characterize two-qubit gate performance across the device.</p> Result interpretation <p>Polling returns EPLGResult with:     - chain_lengths: list of qubit chain lengths tested     - chain_eplgs: EPLG values at each chain length     - eplg_10/20/50/100: EPLG at standard reference points     - score: average EPLG across reference points (lower is better)</p> References <ul> <li>McKay et al., \"Benchmarking quantum processor performance at scale\",   arXiv:2311.05933.</li> <li>Based on qiskit-device-benchmarking layer fidelity notebook.</li> </ul>"},{"location":"benchmarks/overview/#metriq_gym.benchmarks.bseq","title":"<code>bseq</code>","text":"<p>BSEQ (Bell state effective qubits) benchmark implementation.</p> Summary <p>Evaluates how well a device generates Bell pairs that violate the CHSH inequality across its connectivity graph. Circuits are built per colouring of the topology and executed in four measurement bases to detect correlations.</p> Connectivity graph <p>The benchmark uses the device's native connectivity graph to determine which qubit pairs can be coupled. For superconducting devices (e.g., IBM), this reflects the physical coupling map with sparse connectivity. For trapped-ion devices (e.g., IonQ, Quantinuum) and simulators, all-to-all connectivity is assumed (complete graph). The graph structure affects edge coloring: complete graphs with n qubits require n-1 colors (optimal), while sparse topologies typically require fewer colors but test fewer qubit pairs.</p> Result interpretation <p>Polling returns BSEQResult with:     - largest_connected_size: size of the biggest connected subgraph of qubit pairs that       violated CHSH (&gt; 2). Higher means entanglement spans more of the device.     - fraction_connected: largest_connected_size normalised by the discovered qubit count,       making it easier to compare devices of different sizes.</p> References <ul> <li>Original routines attributed to Paul Nation   (Qiskit Device Benchmarking).</li> <li>Clauser et al., Phys. Rev. Lett. 23, 880 (1969).</li> </ul>"},{"location":"benchmarks/overview/#metriq_gym.benchmarks.wit","title":"<code>wit</code>","text":"<p>WIT (wormhole-inspired teleportation) benchmark implementation.</p> Summary <p>Runs a six- or seven-qubit teleportation-inspired circuit that mimics the protocol from Shapoval et al. (2023) and reports a Pauli-Z expectation value with binomial uncertainty.</p> Result interpretation <p>Polling returns WITResult.expectation_value as a BenchmarkScore:     - value: estimated Pauli-Z expectation (ideal teleportation trends toward +1).     - uncertainty: binomial standard deviation computed from the observed counts. Compare value versus uncertainty to decide whether more shots are required or if noise is degrading the teleportation fidelity.</p> References <ul> <li>Shapoval et al., \"Towards Quantum Gravity in the Lab on Quantum Processors\",   Quantum 7, 1138 (2023).</li> <li>Companion script.</li> <li>Implementation lineage credited to Paul Nation (IBM Quantum).</li> </ul>"},{"location":"benchmarks/overview/#metriq_gym.benchmarks.lr_qaoa","title":"<code>lr_qaoa</code>","text":"<p>Linear Ramp QAOA benchmark implementation.</p> Summary <p>Solves weighted Max-Cut instances with a linear-ramp parameter schedule and compares results against classical optima to estimate approximation ratios and optimal sampling probabilities.</p> Result interpretation <p>Polling returns LinearRampQAOAResult with metrics including:     - approx_ratio_mean / stddev: how close average costs are to the optimum.     - optimal_probability_mean / stddev: frequency of sampling an optimal bitstring.     - confidence_pass: boolean indicating whether results meet the configured confidence. Higher approximation ratios and optimal probabilities reflect better QAOA performance.</p> References <ul> <li>Wurtz and Love, \"Counterdiabaticity and the quantum approximate optimization algorithm\",   arXiv:2106.15645.</li> <li>Pelofske et al., arXiv:2405.09169.</li> </ul>"},{"location":"benchmarks/overview/#metriq_gym.benchmarks.qml_kernel","title":"<code>qml_kernel</code>","text":"<p>Quantum Machine Learning Kernel benchmark implementation.</p> Summary <p>Constructs a ZZ feature map kernel, computes the inner-product circuit, and measures the probability of returning to the all-zero state as a proxy for kernel quality.</p> Result interpretation <p>Polling returns QMLKernelResult.accuracy_score as a BenchmarkScore where:     - value: fraction of shots measuring the expected all-zero bitstring.     - uncertainty: binomial standard deviation from the sample counts. Higher accuracy suggests better kernel reproducibility on the selected hardware.</p> References <ul> <li>Inspired by ZZ-feature map approaches, e.g.,   Bowles et al., arXiv:2405.09724.</li> </ul>"},{"location":"benchmarks/overview/#metriq_gym.benchmarks.qedc_benchmarks","title":"<code>qedc_benchmarks</code>","text":"<p>QED-C application-oriented benchmark wrapper.</p> Summary <p>Provides a generic dispatch/poll pipeline around the QED-C benchmark suite (Bernstein- Vazirani, Phase Estimation, Hidden Shift, Quantum Fourier Transform) via the QC-App- Oriented-Benchmarks submodule.</p> Result interpretation <p>Polling returns QEDCResult.circuit_metrics, a nested dictionary keyed by qubit count and circuit identifier, populated with the fidelity or related metrics computed by the QED-C analyser. Inspect the per-circuit entries to understand performance trends.</p> References <ul> <li>QED-C QC-App-Oriented-Benchmarks   repository for algorithm-specific methodology.</li> <li>Lubinski et al., \"Application-Oriented Performance Benchmarks for Quantum Computing\",   IEEE Trans. Quantum Eng. (2023).</li> </ul>"},{"location":"benchmarks/overview/#adding-custom-benchmarks","title":"Adding Custom Benchmarks","text":"<p>See Adding New Benchmarks to contribute new benchmarks.</p>"},{"location":"cli/job-commands/","title":"Job Commands","text":"<p>Commands for dispatching, monitoring, and managing individual benchmark jobs.</p>"},{"location":"cli/job-commands/#dispatch","title":"dispatch","text":"<p>Dispatch a benchmark job to a quantum device or simulator.</p> <pre><code>mgym job dispatch &lt;config&gt; [OPTIONS]\n</code></pre>"},{"location":"cli/job-commands/#arguments","title":"Arguments","text":"Argument Type Description Required <code>CONFIG</code> STR Path to job configuration JSON file Yes"},{"location":"cli/job-commands/#options","title":"Options","text":"Option Type Description Default <code>--provider, -p</code> STR Provider name (e.g., ibm, braket, azure, ionq, local) <code>None</code> <code>--device, -d</code> STR Device identifier <code>None</code>"},{"location":"cli/job-commands/#estimate","title":"estimate","text":"<p>Estimate circuit resource requirements before dispatching jobs.</p> <pre><code>mgym job estimate &lt;config&gt; [OPTIONS]\n</code></pre>"},{"location":"cli/job-commands/#arguments_1","title":"Arguments","text":"Argument Type Description Required <code>CONFIG</code> STR Path to job configuration JSON file Yes"},{"location":"cli/job-commands/#options_1","title":"Options","text":"Option Type Description Default <code>--provider, -p</code> STR Provider name (e.g., ibm, braket, azure, ionq, local) <code>None</code> <code>--device, -d</code> STR Device identifier <code>None</code>"},{"location":"cli/job-commands/#poll","title":"poll","text":"<p>Poll job status and retrieve results when complete.</p> <pre><code>mgym job poll [job_id] [OPTIONS]\n</code></pre>"},{"location":"cli/job-commands/#arguments_2","title":"Arguments","text":"Argument Type Description Required <code>JOB_ID</code> STR Job ID to poll (use 'latest' for most recent) No"},{"location":"cli/job-commands/#options_2","title":"Options","text":"Option Type Description Default <code>--json</code> STR Export results to JSON file <code>None</code> <code>--no-cache</code> BOOL Ignore locally cached results and refetch <code>False</code>"},{"location":"cli/job-commands/#view","title":"view","text":"<p>View job details and metadata.</p> <pre><code>mgym job view [job_id]\n</code></pre>"},{"location":"cli/job-commands/#arguments_3","title":"Arguments","text":"Argument Type Description Required <code>JOB_ID</code> STR Job ID to view (lists all if omitted) No"},{"location":"cli/job-commands/#delete","title":"delete","text":"<p>Delete a job from the local database.</p> <pre><code>mgym job delete [job_id]\n</code></pre>"},{"location":"cli/job-commands/#arguments_4","title":"Arguments","text":"Argument Type Description Required <code>JOB_ID</code> STR Job ID to delete No"},{"location":"cli/job-commands/#upload","title":"upload","text":"<p>Upload job results to GitHub via pull request.</p> <pre><code>mgym job upload [job_id] [OPTIONS]\n</code></pre>"},{"location":"cli/job-commands/#arguments_5","title":"Arguments","text":"Argument Type Description Required <code>JOB_ID</code> STR Job ID to upload No"},{"location":"cli/job-commands/#options_3","title":"Options","text":"Option Type Description Default <code>--repo</code> STR Target GitHub repo (owner/repo) (env: <code>MGYM_UPLOAD_REPO</code>) <code>unitaryfoundation/metriq-data</code> <code>--base</code> STR Base branch for the PR (env: <code>MGYM_UPLOAD_BASE_BRANCH</code>) <code>main</code> <code>--dir</code> STR Directory in repo for the JSON file (env: <code>MGYM_UPLOAD_DIR</code>) <code>None</code> <code>--branch</code> STR Branch name for the PR <code>None</code> <code>--title</code> STR Pull request title <code>None</code> <code>--body</code> STR Pull request body <code>None</code> <code>--commit-message</code> STR Commit message <code>None</code> <code>--clone-dir</code> STR Working directory to clone into (env: <code>MGYM_UPLOAD_CLONE_DIR</code>) <code>None</code> <code>--dry-run</code> BOOL Do not push or open a PR; print actions only <code>False</code>"},{"location":"cli/overview/","title":"CLI Overview","text":"<p>Metriq-Gym provides a command-line interface (<code>mgym</code>) for dispatching, monitoring, and uploading quantum benchmark results.</p>"},{"location":"cli/overview/#installation","title":"Installation","text":"<p>The CLI is installed automatically with metriq-gym:</p> <pre><code>pip install metriq-gym\n</code></pre>"},{"location":"cli/overview/#command-structure","title":"Command Structure","text":"<pre><code>mgym &lt;resource&gt; &lt;action&gt; [arguments] [options]\n</code></pre> <p>Resources: - <code>job</code> - Individual benchmark jobs - <code>suite</code> - Collections of benchmark jobs</p>"},{"location":"cli/overview/#quick-reference","title":"Quick Reference","text":"Command Description <code>mgym job dispatch</code> Dispatch a benchmark job to a quantum device or simulator. <code>mgym job estimate</code> Estimate circuit resource requirements before dispatching jobs. <code>mgym job poll</code> Poll job status and retrieve results when complete. <code>mgym job view</code> View job details and metadata. <code>mgym job delete</code> Delete a job from the local database. <code>mgym job upload</code> Upload job results to GitHub via pull request. <code>mgym suite dispatch</code> Dispatch a suite of benchmark jobs to a quantum device. <code>mgym suite poll</code> Poll suite jobs and retrieve results when complete. <code>mgym suite view</code> View jobs in a suite. <code>mgym suite delete</code> Delete all jobs in a suite from the local database. <code>mgym suite upload</code> Upload suite results to GitHub via pull request."},{"location":"cli/overview/#getting-help","title":"Getting Help","text":"<pre><code># Main help\nmgym --help\n\n# Job commands help\nmgym job --help\n\n# Specific command help\nmgym job dispatch --help\n</code></pre>"},{"location":"cli/suite-commands/","title":"Suite Commands","text":"<p>Commands for dispatching, monitoring, and managing benchmark suites.</p>"},{"location":"cli/suite-commands/#dispatch","title":"dispatch","text":"<p>Dispatch a suite of benchmark jobs to a quantum device.</p> <pre><code>mgym suite dispatch &lt;suite_config&gt; [OPTIONS]\n</code></pre>"},{"location":"cli/suite-commands/#arguments","title":"Arguments","text":"Argument Type Description Required <code>SUITE_CONFIG</code> STR Path to suite configuration file Yes"},{"location":"cli/suite-commands/#options","title":"Options","text":"Option Type Description Default <code>--provider, -p</code> STR Provider name (e.g., ibm, braket, azure, ionq, local) <code>None</code> <code>--device, -d</code> STR Device identifier <code>None</code>"},{"location":"cli/suite-commands/#poll","title":"poll","text":"<p>Poll suite jobs and retrieve results when complete.</p> <pre><code>mgym suite poll [suite_id] [OPTIONS]\n</code></pre>"},{"location":"cli/suite-commands/#arguments_1","title":"Arguments","text":"Argument Type Description Required <code>SUITE_ID</code> STR Suite ID to poll No"},{"location":"cli/suite-commands/#options_1","title":"Options","text":"Option Type Description Default <code>--json</code> STR Export results to JSON file <code>None</code> <code>--no-cache</code> BOOL Ignore locally cached results and refetch <code>False</code>"},{"location":"cli/suite-commands/#view","title":"view","text":"<p>View jobs in a suite.</p> <pre><code>mgym suite view [suite_id]\n</code></pre>"},{"location":"cli/suite-commands/#arguments_2","title":"Arguments","text":"Argument Type Description Required <code>SUITE_ID</code> STR Suite ID to view No"},{"location":"cli/suite-commands/#delete","title":"delete","text":"<p>Delete all jobs in a suite from the local database.</p> <pre><code>mgym suite delete [suite_id]\n</code></pre>"},{"location":"cli/suite-commands/#arguments_3","title":"Arguments","text":"Argument Type Description Required <code>SUITE_ID</code> STR Suite ID to delete No"},{"location":"cli/suite-commands/#upload","title":"upload","text":"<p>Upload suite results to GitHub via pull request.</p> <pre><code>mgym suite upload [suite_id] [OPTIONS]\n</code></pre>"},{"location":"cli/suite-commands/#arguments_4","title":"Arguments","text":"Argument Type Description Required <code>SUITE_ID</code> STR Suite ID to upload No"},{"location":"cli/suite-commands/#options_2","title":"Options","text":"Option Type Description Default <code>--repo</code> STR Target GitHub repo (owner/repo) (env: <code>MGYM_UPLOAD_REPO</code>) <code>unitaryfoundation/metriq-data</code> <code>--base</code> STR Base branch for the PR (env: <code>MGYM_UPLOAD_BASE_BRANCH</code>) <code>main</code> <code>--dir</code> STR Directory in repo for the JSON file (env: <code>MGYM_UPLOAD_DIR</code>) <code>None</code> <code>--branch</code> STR Branch name for the PR <code>None</code> <code>--title</code> STR Pull request title <code>None</code> <code>--body</code> STR Pull request body <code>None</code> <code>--commit-message</code> STR Commit message <code>None</code> <code>--clone-dir</code> STR Working directory to clone into (env: <code>MGYM_UPLOAD_CLONE_DIR</code>) <code>None</code> <code>--dry-run</code> BOOL Do not push or open a PR; print actions only <code>False</code>"},{"location":"development/adding-benchmarks/","title":"Adding New Benchmarks","text":"<p>This guide explains how to integrate a new benchmark into Metriq-Gym.</p>"},{"location":"development/adding-benchmarks/#overview","title":"Overview","text":"<p>Adding a benchmark involves:</p> <ol> <li>Creating Python classes (Benchmark, Data, Result)</li> <li>Defining a JSON Schema for configuration</li> <li>Providing an example configuration</li> <li>Registering the benchmark in the system</li> </ol>"},{"location":"development/adding-benchmarks/#step-1-create-the-benchmark-class","title":"Step 1: Create the Benchmark Class","text":"<p>Create a new file in <code>metriq_gym/benchmarks/</code>:</p> <pre><code># metriq_gym/benchmarks/my_benchmark.py\n\nfrom dataclasses import dataclass\nfrom qbraid.runtime import QuantumDevice, GateModelResultData\n\nfrom metriq_gym.benchmarks.benchmark import (\n    Benchmark,\n    BenchmarkData,\n    BenchmarkResult,\n    BenchmarkScore,\n)\n\n\n@dataclass\nclass MyBenchmarkResult(BenchmarkResult):\n    \"\"\"Stores the results from running My Benchmark.\"\"\"\n\n    # Simple numeric metric\n    success_rate: float\n\n    # Metric with uncertainty\n    fidelity: BenchmarkScore\n\n\n@dataclass\nclass MyBenchmarkData(BenchmarkData):\n    \"\"\"Stores intermediate data for My Benchmark.\"\"\"\n\n    # Data needed between dispatch and poll\n    expected_outputs: list[str]\n    num_circuits: int\n\n\nclass MyBenchmark(Benchmark):\n    \"\"\"Benchmark implementation for My Benchmark.\"\"\"\n\n    def dispatch_handler(self, device: QuantumDevice) -&gt; MyBenchmarkData:\n        \"\"\"Create and submit benchmark circuits.\n\n        Args:\n            device: The quantum device to run on\n\n        Returns:\n            Data needed for result analysis\n        \"\"\"\n        # Access configuration via self.config\n        num_qubits = self.config.get(\"num_qubits\", 5)\n        shots = self.config.get(\"shots\", 1000)\n\n        # Create circuits\n        circuits = self._create_circuits(num_qubits)\n\n        # Submit to device (handled by base class)\n        # Just return the circuits and metadata\n\n        return MyBenchmarkData(\n            expected_outputs=[\"00000\"] * len(circuits),\n            num_circuits=len(circuits),\n        )\n\n    def poll_handler(\n        self,\n        job_data: BenchmarkData,\n        result_data: list[GateModelResultData]\n    ) -&gt; MyBenchmarkResult:\n        \"\"\"Process results and compute metrics.\n\n        Args:\n            job_data: Data from dispatch phase\n            result_data: Raw measurement results\n\n        Returns:\n            Computed benchmark results\n        \"\"\"\n        data = job_data  # Cast to MyBenchmarkData\n\n        # Analyze results\n        successes = 0\n        for i, result in enumerate(result_data):\n            counts = result.measurements\n            if data.expected_outputs[i] in counts:\n                successes += counts[data.expected_outputs[i]]\n\n        total_shots = sum(sum(r.measurements.values()) for r in result_data)\n        success_rate = successes / total_shots\n\n        # Calculate fidelity with uncertainty\n        fidelity_val = self._calculate_fidelity(result_data)\n        fidelity_unc = self._calculate_uncertainty(result_data)\n\n        return MyBenchmarkResult(\n            success_rate=success_rate,\n            fidelity=BenchmarkScore(value=fidelity_val, uncertainty=fidelity_unc),\n        )\n\n    def _create_circuits(self, num_qubits: int):\n        \"\"\"Create benchmark circuits.\"\"\"\n        # Implementation details...\n        pass\n\n    def _calculate_fidelity(self, results):\n        \"\"\"Calculate fidelity metric.\"\"\"\n        pass\n\n    def _calculate_uncertainty(self, results):\n        \"\"\"Calculate statistical uncertainty.\"\"\"\n        pass\n</code></pre>"},{"location":"development/adding-benchmarks/#step-2-define-the-json-schema","title":"Step 2: Define the JSON Schema","text":"<p>Create <code>metriq_gym/schemas/my_benchmark.schema.json</code>:</p> <pre><code>{\n  \"$id\": \"metriq-gym/my_benchmark.schema.json\",\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"title\": \"My Benchmark\",\n  \"description\": \"Schema for My Benchmark configuration.\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"benchmark_name\": {\n      \"type\": \"string\",\n      \"const\": \"My Benchmark\",\n      \"description\": \"Must be 'My Benchmark'\"\n    },\n    \"num_qubits\": {\n      \"type\": \"integer\",\n      \"description\": \"Number of qubits to use\",\n      \"minimum\": 1,\n      \"examples\": [5]\n    },\n    \"shots\": {\n      \"type\": \"integer\",\n      \"description\": \"Measurement shots per circuit\",\n      \"default\": 1000,\n      \"minimum\": 1,\n      \"examples\": [1000]\n    },\n    \"custom_param\": {\n      \"type\": \"number\",\n      \"description\": \"A custom parameter for this benchmark\",\n      \"default\": 0.5,\n      \"minimum\": 0.0,\n      \"maximum\": 1.0\n    }\n  },\n  \"required\": [\"benchmark_name\", \"num_qubits\"]\n}\n</code></pre>"},{"location":"development/adding-benchmarks/#step-3-create-example-configuration","title":"Step 3: Create Example Configuration","text":"<p>Create <code>metriq_gym/schemas/examples/my_benchmark.example.json</code>:</p> <pre><code>{\n  \"benchmark_name\": \"My Benchmark\",\n  \"num_qubits\": 5,\n  \"shots\": 1000,\n  \"custom_param\": 0.5\n}\n</code></pre>"},{"location":"development/adding-benchmarks/#step-4-register-the-benchmark","title":"Step 4: Register the Benchmark","text":""},{"location":"development/adding-benchmarks/#add-to-constantspy","title":"Add to constants.py","text":"<pre><code># metriq_gym/constants.py\n\nclass JobType(StrEnum):\n    # ... existing entries ...\n    MY_BENCHMARK = \"My Benchmark\"\n\n\nSCHEMA_MAPPING = {\n    # ... existing entries ...\n    JobType.MY_BENCHMARK: \"my_benchmark.schema.json\",\n}\n</code></pre>"},{"location":"development/adding-benchmarks/#add-to-registrypy","title":"Add to registry.py","text":"<pre><code># metriq_gym/registry.py\n\nfrom metriq_gym.benchmarks.my_benchmark import MyBenchmark, MyBenchmarkData\n\nBENCHMARK_HANDLERS: dict[JobType, type[Benchmark]] = {\n    # ... existing entries ...\n    JobType.MY_BENCHMARK: MyBenchmark,\n}\n\nBENCHMARK_DATA_CLASSES: dict[JobType, type[BenchmarkData]] = {\n    # ... existing entries ...\n    JobType.MY_BENCHMARK: MyBenchmarkData,\n}\n</code></pre>"},{"location":"development/adding-benchmarks/#result-metrics","title":"Result Metrics","text":""},{"location":"development/adding-benchmarks/#simple-numeric-metrics","title":"Simple Numeric Metrics","text":"<p>For metrics without uncertainty:</p> <pre><code>@dataclass\nclass MyResult(BenchmarkResult):\n    score: float  # No uncertainty\n</code></pre>"},{"location":"development/adding-benchmarks/#metrics-with-uncertainty","title":"Metrics with Uncertainty","text":"<p>For metrics with statistical uncertainty:</p> <pre><code>@dataclass\nclass MyResult(BenchmarkResult):\n    fidelity: BenchmarkScore  # Has value and uncertainty\n</code></pre> <p>Usage: <pre><code>return MyResult(\n    fidelity=BenchmarkScore(value=0.95, uncertainty=0.02)\n)\n</code></pre></p>"},{"location":"development/adding-benchmarks/#result-export","title":"Result Export","text":"<p>The exporter automatically creates:</p> <pre><code>{\n  \"results\": {\n    \"values\": {\n      \"score\": 0.85,\n      \"fidelity\": 0.95\n    },\n    \"uncertainties\": {\n      \"fidelity\": 0.02\n    }\n  }\n}\n</code></pre>"},{"location":"development/adding-benchmarks/#best-practices","title":"Best Practices","text":""},{"location":"development/adding-benchmarks/#configuration","title":"Configuration","text":"<ul> <li>Use sensible defaults for optional parameters</li> <li>Validate parameters in <code>dispatch_handler</code></li> <li>Document all parameters in the schema</li> </ul>"},{"location":"development/adding-benchmarks/#circuit-creation","title":"Circuit Creation","text":"<ul> <li>Use Qiskit circuits for portability</li> <li>Respect device topology when possible</li> <li>Keep circuits transpiler-friendly</li> </ul>"},{"location":"development/adding-benchmarks/#result-analysis","title":"Result Analysis","text":"<ul> <li>Calculate meaningful uncertainty estimates</li> <li>Handle edge cases (zero shots, failed circuits)</li> <li>Return <code>None</code> for undefined metrics</li> </ul>"},{"location":"development/adding-benchmarks/#testing","title":"Testing","text":"<p>Create tests in <code>tests/test_benchmarks.py</code>:</p> <pre><code>def test_my_benchmark_dispatch():\n    config = {\"benchmark_name\": \"My Benchmark\", \"num_qubits\": 5}\n    benchmark = MyBenchmark(config)\n    data = benchmark.dispatch_handler(mock_device)\n    assert data.num_circuits &gt; 0\n\ndef test_my_benchmark_poll():\n    # Test result processing\n    ...\n</code></pre>"},{"location":"development/adding-benchmarks/#checklist","title":"Checklist","text":"<p>Before submitting your benchmark:</p> <ul> <li>[ ] Benchmark class implements <code>dispatch_handler</code> and <code>poll_handler</code></li> <li>[ ] JSON Schema validates all configuration options</li> <li>[ ] Example configuration works with local simulator</li> <li>[ ] Benchmark registered in <code>constants.py</code> and <code>registry.py</code></li> <li>[ ] Tests cover dispatch and poll logic</li> <li>[ ] Documentation explains benchmark purpose and metrics</li> </ul>"},{"location":"development/api-reference/","title":"API Reference","text":"<p>This page documents the main Python modules in Metriq-Gym.</p>"},{"location":"development/api-reference/#core-modules","title":"Core Modules","text":""},{"location":"development/api-reference/#metriq_gymrun","title":"metriq_gym.run","text":"<p>Main runtime module with dispatch, poll, and upload functions.</p> <p>Runtime entrypoints for dispatching and managing metriq-gym benchmarks via the CLI.</p>"},{"location":"development/api-reference/#metriq_gym.run.dispatch_job","title":"<code>dispatch_job(args, job_manager)</code>","text":"<p>Dispatch a single benchmark configuration to a quantum device.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>CLI arguments with benchmark config, provider, and device</p> required <code>job_manager</code> <code>JobManager</code> <p>Tracks dispatched jobs for later polling</p> required <p>Note: Continues processing remaining configs if individual configs fail.</p>"},{"location":"development/api-reference/#metriq_gym.run.poll_job","title":"<code>poll_job(args, job_manager)</code>","text":""},{"location":"development/api-reference/#metriq_gym.run.upload_job","title":"<code>upload_job(args, job_manager)</code>","text":"<p>Upload a job's results to a GitHub repo by opening a Pull Request.</p>"},{"location":"development/api-reference/#metriq_gym.run.view_job","title":"<code>view_job(args, job_manager)</code>","text":""},{"location":"development/api-reference/#metriq_gym.run.load_provider","title":"<code>load_provider(provider_name)</code>","text":"<p>Lazy proxy to qbraid.runtime.load_provider.</p> <p>Exposed at module level so tests can monkeypatch <code>metriq_gym.run.load_provider</code>.</p>"},{"location":"development/api-reference/#metriq_gym.run.setup_device","title":"<code>setup_device(provider_name, device_name)</code>","text":"<p>Setup a QBraid device with id device_name from specified provider.</p> <p>Parameters:</p> Name Type Description Default <code>provider_name</code> <code>str</code> <p>a metriq-gym supported provider name.</p> required <code>device_name</code> <code>str</code> <p>the id of a device supported by the provider.</p> required <p>Raises:     QBraidSetupError: If no device matching the name is found in the provider.</p>"},{"location":"development/api-reference/#metriq_gymcli","title":"metriq_gym.cli","text":"<p>Command-line interface utilities.</p> <p>Command-line interface for running Metriq-Gym benchmarks using Typer.</p> Usage overview <ul> <li>Dispatch a single job:     mgym job dispatch path/to/config.json -p  -d  <li>Poll latest job and write JSON results:     mgym job poll latest --json results.json</li> <li>Dispatch a suite of jobs:     mgym suite dispatch path/to/suite.json -p  -d  <li>Poll a suite:     mgym suite poll  <li>Dry-run upload (no network):     mgym job upload latest --dry-run</li>"},{"location":"development/api-reference/#metriq_gym.cli.job_delete","title":"<code>job_delete(job_id=None)</code>","text":"<p>Delete a job from the local database.</p> <p>Note: This only removes the job from local tracking. It does not cancel jobs running on quantum hardware.</p>"},{"location":"development/api-reference/#metriq_gym.cli.job_dispatch","title":"<code>job_dispatch(config, provider=None, device=None)</code>","text":"<p>Dispatch a benchmark job to a quantum device or simulator.</p>"},{"location":"development/api-reference/#metriq_gym.cli.job_estimate","title":"<code>job_estimate(config, provider=None, device=None)</code>","text":"<p>Estimate circuit resource requirements before dispatching jobs.</p> <p>This is especially useful for understanding costs on paid hardware like Quantinuum. For Quantinuum providers, calculates H-series Quantum Credits (HQCs).</p>"},{"location":"development/api-reference/#metriq_gym.cli.job_poll","title":"<code>job_poll(job_id=None, json_output=None, no_cache=False)</code>","text":"<p>Poll job status and retrieve results when complete.</p>"},{"location":"development/api-reference/#metriq_gym.cli.job_upload","title":"<code>job_upload(job_id=None, repo='unitaryfoundation/metriq-data', base_branch='main', upload_dir=None, branch_name=None, pr_title=None, pr_body=None, commit_message=None, clone_dir=None, dry_run=False)</code>","text":"<p>Upload job results to GitHub via pull request.</p>"},{"location":"development/api-reference/#metriq_gym.cli.job_view","title":"<code>job_view(job_id=None)</code>","text":"<p>View job details and metadata.</p>"},{"location":"development/api-reference/#metriq_gym.cli.list_jobs","title":"<code>list_jobs(jobs, show_index=False, show_suite_id=True)</code>","text":"<p>List jobs recorded in the job manager.</p> <p>Parameters:</p> Name Type Description Default <code>jobs</code> <code>list[MetriqGymJob]</code> <p>List of MetriqGymJob instances.</p> required <code>show_index</code> <code>bool</code> <p>Whether to show the job index in the output table.</p> <code>False</code> <code>show_suite_id</code> <code>bool</code> <p>Whether to show the suite ID column.</p> <code>True</code>"},{"location":"development/api-reference/#metriq_gym.cli.prompt_for_job","title":"<code>prompt_for_job(job_id, job_manager)</code>","text":"<p>Prompt user to select a job if job_id is not provided.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>Optional[str]</code> <p>Optional job ID or 'latest'.</p> required <code>job_manager</code> <code>JobManager</code> <p>JobManager instance.</p> required <p>Returns:</p> Type Description <code>MetriqGymJob | None</code> <p>Selected MetriqGymJob or None.</p>"},{"location":"development/api-reference/#metriq_gym.cli.suite_delete","title":"<code>suite_delete(suite_id=None)</code>","text":"<p>Delete all jobs in a suite from the local database.</p>"},{"location":"development/api-reference/#metriq_gym.cli.suite_dispatch","title":"<code>suite_dispatch(suite_config, provider=None, device=None)</code>","text":"<p>Dispatch a suite of benchmark jobs to a quantum device.</p>"},{"location":"development/api-reference/#metriq_gym.cli.suite_poll","title":"<code>suite_poll(suite_id=None, json_output=None, no_cache=False)</code>","text":"<p>Poll suite jobs and retrieve results when complete.</p>"},{"location":"development/api-reference/#metriq_gym.cli.suite_upload","title":"<code>suite_upload(suite_id=None, repo='unitaryfoundation/metriq-data', base_branch='main', upload_dir=None, branch_name=None, pr_title=None, pr_body=None, commit_message=None, clone_dir=None, dry_run=False)</code>","text":"<p>Upload suite results to GitHub via pull request.</p>"},{"location":"development/api-reference/#metriq_gym.cli.suite_view","title":"<code>suite_view(suite_id=None)</code>","text":"<p>View jobs in a suite.</p>"},{"location":"development/api-reference/#metriq_gymjob_manager","title":"metriq_gym.job_manager","text":"<p>Job tracking and persistence.</p> <p>Local persistence and helpers for tracking dispatched metriq-gym jobs.</p>"},{"location":"development/api-reference/#metriq_gym.job_manager.JobManager","title":"<code>JobManager</code>","text":""},{"location":"development/api-reference/#metriq_gym.job_manager.JobManager.update_job","title":"<code>update_job(updated_job)</code>","text":"<p>Persist updated job information to disk.</p>"},{"location":"development/api-reference/#metriq_gym.job_manager.MetriqGymJob","title":"<code>MetriqGymJob</code>  <code>dataclass</code>","text":""},{"location":"development/api-reference/#metriq_gym.job_manager.MetriqGymJob.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Keep platform and provider/device fields in sync on initialization.</p> <ul> <li>If platform is missing, populate from provider_name/device_name.</li> <li>If platform exists but lacks keys, backfill them from provider/device fields.</li> </ul>"},{"location":"development/api-reference/#metriq_gymschema_validator","title":"metriq_gym.schema_validator","text":"<p>JSON Schema validation utilities.</p> <p>Schema loading and validation utilities for metriq-gym benchmark configurations.</p>"},{"location":"development/api-reference/#metriq_gym.schema_validator.create_pydantic_model","title":"<code>create_pydantic_model(schema)</code>","text":"<p>Create a Pydantic model from a JSON schema.</p>"},{"location":"development/api-reference/#metriq_gym.schema_validator.load_and_validate","title":"<code>load_and_validate(file_path, schema_dir=DEFAULT_SCHEMA_DIR)</code>","text":"<p>Load parameters from a JSON file and validate them against the corresponding schema.</p> <p>Raises a ValidationError if validation fails.</p>"},{"location":"development/api-reference/#metriq_gym.schema_validator.load_json_file","title":"<code>load_json_file(file_path)</code>","text":"<p>Load and parse a JSON file.</p>"},{"location":"development/api-reference/#metriq_gym.schema_validator.load_schema","title":"<code>load_schema(benchmark_name, schema_dir=DEFAULT_SCHEMA_DIR)</code>","text":"<p>Load a JSON schema based on the benchmark name.</p> <p>Uses package resources for installed distributions; falls back to local path.</p>"},{"location":"development/api-reference/#metriq_gymsuite_parser","title":"metriq_gym.suite_parser","text":"<p>Benchmark suite parsing.</p> <p>Parsing helpers for benchmark suite definitions.</p>"},{"location":"development/api-reference/#metriq_gym.suite_parser.parse_suite_file","title":"<code>parse_suite_file(path)</code>","text":"<p>Parse a suite JSON file and return a Suite object.</p>"},{"location":"development/api-reference/#key-classes","title":"Key Classes","text":""},{"location":"development/api-reference/#jobmanager","title":"JobManager","text":"<p>Manages job lifecycle and persistence.</p> <pre><code>from metriq_gym.job_manager import JobManager\n\nmanager = JobManager()\n\n# Get all jobs\njobs = manager.get_jobs()\n\n# Get specific job\njob = manager.get_job(\"job-id\")\n\n# Add a new job\nmanager.add_job(job)\n\n# Update job status\nmanager.update_job(job)\n</code></pre>"},{"location":"development/api-reference/#metriqgymjob","title":"MetriqGymJob","text":"<p>Represents a benchmark job.</p> <pre><code>from metriq_gym.job_manager import MetriqGymJob\n\njob = MetriqGymJob(\n    id=\"unique-id\",\n    job_type=JobType.QUANTUM_VOLUME,\n    params={\"num_qubits\": 5, \"shots\": 1000},\n    provider_name=\"ibm\",\n    device_name=\"ibm_sherbrooke\",\n    provider_job_ids=[\"remote-job-id\"],\n    dispatch_time=\"2025-01-15T12:00:00\",\n    app_version=\"0.3.1\",\n)\n</code></pre>"},{"location":"development/api-reference/#benchmark-base-classes","title":"Benchmark Base Classes","text":""},{"location":"development/api-reference/#benchmark","title":"Benchmark","text":"<p>Base class for all benchmarks.</p> <pre><code>from metriq_gym.benchmarks.benchmark import Benchmark\n\nclass MyBenchmark(Benchmark):\n    def dispatch_handler(self, device):\n        # Create and submit circuits\n        pass\n\n    def poll_handler(self, job_data, result_data):\n        # Process results\n        pass\n</code></pre>"},{"location":"development/api-reference/#benchmarkresult","title":"BenchmarkResult","text":"<p>Base class for benchmark results.</p> <pre><code>from dataclasses import dataclass\nfrom metriq_gym.benchmarks.benchmark import BenchmarkResult\n\n@dataclass\nclass MyResult(BenchmarkResult):\n    metric_value: float\n</code></pre>"},{"location":"development/api-reference/#benchmarkscore","title":"BenchmarkScore","text":"<p>Metric with uncertainty.</p> <pre><code>from metriq_gym.benchmarks.benchmark import BenchmarkScore\n\nscore = BenchmarkScore(value=0.95, uncertainty=0.02)\n</code></pre>"},{"location":"development/api-reference/#exporter-classes","title":"Exporter Classes","text":""},{"location":"development/api-reference/#githubprexporter","title":"GitHubPRExporter","text":"<p>Exports results to GitHub via pull request.</p> <pre><code>from metriq_gym.exporters.github_pr_exporter import GitHubPRExporter\n\nexporter = GitHubPRExporter(job, result)\npr_url = exporter.export(\n    repo=\"unitaryfoundation/metriq-data\",\n    base_branch=\"main\",\n    directory=\"results/\",\n)\n</code></pre>"},{"location":"development/api-reference/#jsonexporter","title":"JSONExporter","text":"<p>Exports results to local JSON file.</p> <pre><code>from metriq_gym.exporters.json_exporter import JSONExporter\n\nexporter = JSONExporter(job, result)\nexporter.export(output_path=\"result.json\")\n</code></pre>"},{"location":"development/api-reference/#constants","title":"Constants","text":""},{"location":"development/api-reference/#jobtype","title":"JobType","text":"<p>Enum of supported benchmark types.</p> <pre><code>from metriq_gym.constants import JobType\n\nJobType.QUANTUM_VOLUME  # \"Quantum Volume\"\nJobType.CLOPS           # \"CLOPS\"\nJobType.BSEQ            # \"BSEQ\"\nJobType.WIT             # \"WIT\"\n# ... etc\n</code></pre>"},{"location":"development/api-reference/#schema_mapping","title":"SCHEMA_MAPPING","text":"<p>Maps JobType to schema files.</p> <pre><code>from metriq_gym.constants import SCHEMA_MAPPING\n\nschema_file = SCHEMA_MAPPING[JobType.QUANTUM_VOLUME]\n# \"quantum_volume.schema.json\"\n</code></pre>"},{"location":"development/api-reference/#usage-examples","title":"Usage Examples","text":""},{"location":"development/api-reference/#dispatch-and-poll","title":"Dispatch and Poll","text":"<pre><code>from types import SimpleNamespace\nfrom dotenv import load_dotenv\nfrom metriq_gym.run import dispatch_job, poll_job\nfrom metriq_gym.job_manager import JobManager\n\nload_dotenv()\njob_manager = JobManager()\n\n# Dispatch\ndispatch_config = SimpleNamespace(\n    config=\"metriq_gym/schemas/examples/wit.example.json\",\n    provider=\"local\",\n    device=\"aer_simulator\",\n)\ndispatch_job(dispatch_config, job_manager)\n\n# Poll\njobs = job_manager.get_jobs()\npoll_config = SimpleNamespace(job_id=jobs[-1].id)\npoll_job(poll_config, job_manager)\n</code></pre>"},{"location":"development/api-reference/#custom-provider-setup","title":"Custom Provider Setup","text":"<pre><code>from metriq_gym.run import load_provider, setup_device\n\n# Load provider\nprovider = load_provider(\"ibm\")\n\n# Get device\ndevice = setup_device(\"ibm\", \"ibm_sherbrooke\")\n\n# List available devices\ndevices = provider.get_devices()\nfor d in devices:\n    print(f\"{d.id}: {d.status}\")\n</code></pre>"},{"location":"development/api-reference/#working-with-results","title":"Working with Results","text":"<pre><code>from metriq_gym.job_manager import JobManager\n\nmanager = JobManager()\njob = manager.get_job(\"job-id\")\n\n# Access result data\nif job.result_data:\n    print(job.result_data)\n</code></pre>"},{"location":"development/developer-guide/","title":"Developer Guide","text":"<p>This guide covers setting up a development environment for contributing to Metriq-Gym.</p>"},{"location":"development/developer-guide/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>Python (version 3.12 or newer)</li> <li>uv for dependency management</li> <li>Git for version control</li> </ul>"},{"location":"development/developer-guide/#getting-started","title":"Getting Started","text":""},{"location":"development/developer-guide/#clone-the-repository","title":"Clone the Repository","text":"<p>Clone with submodules:</p> <pre><code>git clone --recurse-submodules https://github.com/unitaryfoundation/metriq-gym.git\ncd metriq-gym\n</code></pre> <p>If you already have a clone, update it:</p> <pre><code>git pull --recurse-submodules\n</code></pre>"},{"location":"development/developer-guide/#install-dependencies","title":"Install Dependencies","text":"<p>Install all dependencies including dev tools:</p> <pre><code>uv sync --all-groups\n</code></pre> <p>This creates a virtual environment in <code>.venv</code> and installs all dependencies.</p>"},{"location":"development/developer-guide/#activate-environment","title":"Activate Environment","text":"<p>Either activate the virtual environment:</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>Or use <code>uv run</code> for isolated commands:</p> <pre><code>uv run pytest\n</code></pre>"},{"location":"development/developer-guide/#macos-note","title":"macOS Note","text":"<p>macOS users installing optional <code>pyqpanda3</code> support must install <code>libidn2</code>:</p> <pre><code>brew reinstall libidn2\n</code></pre> <p>Install this before running <code>uv sync</code> to avoid build errors.</p>"},{"location":"development/developer-guide/#development-workflow","title":"Development Workflow","text":""},{"location":"development/developer-guide/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Install pre-commit hooks after cloning:</p> <pre><code>uv run pre-commit install\n</code></pre> <p>This runs linting and formatting automatically on each commit.</p>"},{"location":"development/developer-guide/#running-tests","title":"Running Tests","text":"<pre><code># All tests\nuv run pytest\n\n# Unit tests only\nuv run pytest -m \"not e2e\"\n\n# End-to-end tests only\nuv run pytest -m e2e\n\n# Specific test file\nuv run pytest tests/test_benchmarks.py\n</code></pre>"},{"location":"development/developer-guide/#linting-and-formatting","title":"Linting and Formatting","text":"<pre><code># Run ruff linter\nuv run ruff check .\n\n# Run ruff formatter\nuv run ruff format .\n\n# Check types with mypy\nuv run mypy\n</code></pre>"},{"location":"development/developer-guide/#building-documentation","title":"Building Documentation","text":"<pre><code>cd docs\nuv run mkdocs serve\n</code></pre> <p>Open <code>http://127.0.0.1:8000</code> to view the documentation locally.</p>"},{"location":"development/developer-guide/#project-structure","title":"Project Structure","text":"<pre><code>metriq-gym/\n\u251c\u2500\u2500 metriq_gym/\n\u2502   \u251c\u2500\u2500 benchmarks/      # Benchmark implementations\n\u2502   \u251c\u2500\u2500 exporters/       # Result export (JSON, GitHub PR)\n\u2502   \u251c\u2500\u2500 local/           # Local simulator provider\n\u2502   \u251c\u2500\u2500 origin/          # OriginQ provider\n\u2502   \u251c\u2500\u2500 quantinuum/      # Quantinuum provider\n\u2502   \u251c\u2500\u2500 schemas/         # JSON schemas and examples\n\u2502   \u251c\u2500\u2500 cli.py           # CLI argument parsing\n\u2502   \u251c\u2500\u2500 constants.py     # JobType enum, schema mapping\n\u2502   \u251c\u2500\u2500 job_manager.py   # Job tracking\n\u2502   \u251c\u2500\u2500 registry.py      # Benchmark registration\n\u2502   \u2514\u2500\u2500 run.py           # Main entrypoint\n\u251c\u2500\u2500 tests/               # Test suite\n\u251c\u2500\u2500 docs/                # Documentation\n\u251c\u2500\u2500 submodules/          # External dependencies\n\u2514\u2500\u2500 pyproject.toml       # Project configuration\n</code></pre>"},{"location":"development/developer-guide/#contributing","title":"Contributing","text":""},{"location":"development/developer-guide/#contribution-workflow","title":"Contribution Workflow","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Run tests and linting</li> <li>Submit a pull request</li> </ol>"},{"location":"development/developer-guide/#commit-style","title":"Commit Style","text":"<p>Follow Conventional Commits:</p> <pre><code>feat: add support for new benchmark type\nfix: correct quantum volume calculation\ndocs: update provider setup guide\nrefactor: simplify job manager interface\n</code></pre>"},{"location":"development/developer-guide/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<ul> <li>Rebase onto the latest <code>main</code> before opening a PR</li> <li>Link related issues or discussions</li> <li>Include CLI output or screenshots for user-facing changes</li> <li>Ensure all tests pass</li> <li>Get approval from maintainers</li> </ul>"},{"location":"development/developer-guide/#code-style","title":"Code Style","text":"<p>The project uses: - Ruff for linting and formatting - mypy for type checking - Line length: 100 characters</p>"},{"location":"development/developer-guide/#type-annotations","title":"Type Annotations","text":"<p>Use type annotations for all public functions:</p> <pre><code>def dispatch_job(config: SimpleNamespace, job_manager: JobManager) -&gt; str:\n    \"\"\"Dispatch a benchmark job.\n\n    Args:\n        config: Job configuration with provider, device, and config path\n        job_manager: Job tracking instance\n\n    Returns:\n        The metriq-gym job ID\n    \"\"\"\n    ...\n</code></pre>"},{"location":"development/developer-guide/#testing","title":"Testing","text":""},{"location":"development/developer-guide/#test-categories","title":"Test Categories","text":"Marker Description (none) Unit tests (fast, no external dependencies) <code>e2e</code> End-to-end tests (may require credentials)"},{"location":"development/developer-guide/#writing-tests","title":"Writing Tests","text":"<pre><code>import pytest\nfrom metriq_gym.benchmarks.wit import WIT\n\ndef test_wit_dispatch():\n    \"\"\"Test WIT benchmark dispatch creates correct circuits.\"\"\"\n    benchmark = WIT(config)\n    result = benchmark.dispatch_handler(mock_device)\n    assert result.circuits is not None\n\n@pytest.mark.e2e\ndef test_wit_full_workflow():\n    \"\"\"Test full WIT workflow on simulator.\"\"\"\n    # This test requires local simulator\n    ...\n</code></pre>"},{"location":"development/developer-guide/#debugging","title":"Debugging","text":""},{"location":"development/developer-guide/#verbose-logging","title":"Verbose Logging","text":"<p>Enable debug logging:</p> <pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre>"},{"location":"development/developer-guide/#local-testing","title":"Local Testing","text":"<p>Test against the local simulator:</p> <pre><code>mgym job dispatch metriq_gym/schemas/examples/wit.example.json \\\n    -p local -d aer_simulator\n</code></pre>"},{"location":"development/developer-guide/#release-process","title":"Release Process","text":"<p>Releases are managed by maintainers:</p> <ol> <li>Version is determined by <code>setuptools_scm</code> from git tags</li> <li>CI builds and publishes to PyPI</li> <li>Documentation is deployed to GitHub Pages</li> </ol>"},{"location":"development/developer-guide/#getting-help","title":"Getting Help","text":"<ul> <li>Issue Tracker</li> <li>Discussions</li> <li>CONTRIBUTING.md</li> </ul>"},{"location":"getting-started/metriq-platform/","title":"Metriq Platform","text":"<p>This page explains how your uploaded results appear on the Metriq platform.</p> <p>Tip</p> <p>For an overview of Metriq-Gym, see the home page.</p>"},{"location":"getting-started/metriq-platform/#metriqinfo","title":"Metriq.info","text":"<p>Visit metriq.info to explore:</p> <ul> <li>Historical benchmark results across devices</li> <li>Performance trends over time</li> <li>Device comparisons</li> <li>Community contributions</li> </ul> <p>Note</p> <p>The Metriq platform is currently available at beta.metriq.info. The URL will transition to metriq.info at launch.</p>"},{"location":"getting-started/metriq-platform/#how-results-appear","title":"How Results Appear","text":""},{"location":"getting-started/metriq-platform/#result-discovery","title":"Result Discovery","text":"<p>The metriq-data repository is periodically scanned for new results. Merged PRs are automatically processed.</p>"},{"location":"getting-started/metriq-platform/#result-display","title":"Result Display","text":"<p>Results are displayed with:</p> <ul> <li>Device and provider information</li> <li>Benchmark type and parameters</li> <li>Metric values with uncertainties</li> <li>Timestamp and software version</li> </ul>"},{"location":"getting-started/metriq-platform/#historical-tracking","title":"Historical Tracking","text":"<p>The platform tracks results over time, allowing you to see:</p> <ul> <li>How device performance changes</li> <li>Calibration effects</li> <li>Long-term trends</li> </ul>"},{"location":"getting-started/metriq-platform/#data-format","title":"Data Format","text":"<p>Results in metriq-data follow a standardized format:</p> <pre><code>{\n  \"app_version\": \"0.3.1\",\n  \"timestamp\": \"2025-01-15T12:00:00.000000\",\n  \"platform\": {\n    \"provider\": \"ibm\",\n    \"device\": \"ibm_sherbrooke\"\n  },\n  \"job_type\": \"Quantum Volume\",\n  \"results\": {\n    \"values\": {\n      \"quantum_volume\": 32,\n      \"heavy_output_probability\": 0.68\n    },\n    \"uncertainties\": {\n      \"heavy_output_probability\": 0.02\n    }\n  },\n  \"params\": {\n    \"benchmark_name\": \"Quantum Volume\",\n    \"num_qubits\": 5,\n    \"shots\": 1000,\n    \"trials\": 100\n  }\n}\n</code></pre>"},{"location":"getting-started/metriq-platform/#key-fields","title":"Key Fields","text":"Field Description <code>app_version</code> Metriq-Gym version used <code>timestamp</code> When the benchmark was run <code>platform.provider</code> Hardware provider <code>platform.device</code> Specific device <code>job_type</code> Benchmark type <code>results.values</code> Metric values <code>results.uncertainties</code> Statistical uncertainties <code>params</code> Benchmark configuration"},{"location":"getting-started/metriq-platform/#contributing-quality-data","title":"Contributing Quality Data","text":"<p>To ensure your results are valuable:</p>"},{"location":"getting-started/metriq-platform/#do","title":"Do","text":"<ul> <li>Run benchmarks with sufficient shots for statistical significance</li> <li>Use recommended trial counts for your benchmark</li> <li>Include all relevant parameters</li> <li>Verify results before uploading</li> </ul>"},{"location":"getting-started/metriq-platform/#dont","title":"Don't","text":"<ul> <li>Upload test runs or debugging data</li> <li>Artificially cherry-pick results</li> <li>Modify result files manually</li> <li>Upload duplicate results</li> </ul>"},{"location":"getting-started/metriq-platform/#metriq-data-repository","title":"metriq-data Repository","text":"<p>The unitaryfoundation/metriq-data repository:</p> <ul> <li>Is open source and community-driven</li> <li>Accepts contributions via pull requests</li> <li>Uses automated validation</li> <li>Is backed up regularly</li> </ul>"},{"location":"getting-started/metriq-platform/#directory-structure","title":"Directory Structure","text":"<pre><code>metriq-data/\n\u251c\u2500\u2500 metriq-gym/\n\u2502   \u251c\u2500\u2500 v0.3/\n\u2502   \u2502   \u251c\u2500\u2500 ibm/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ibm_sherbrooke/\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 2025-01-15T12:00:00_BSEQ_abc123.json\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 ibm_fez/\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 ...\n\u2502   \u2502   \u251c\u2500\u2500 ionq/\n\u2502   \u2502   \u2514\u2500\u2500 local/\n\u2502   \u2514\u2500\u2500 v0.4/\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"getting-started/metriq-platform/#accessing-data","title":"Accessing Data","text":""},{"location":"getting-started/metriq-platform/#via-github","title":"Via GitHub","text":"<p>Browse or clone the repository:</p> <pre><code>git clone https://github.com/unitaryfoundation/metriq-data.git\n</code></pre>"},{"location":"getting-started/metriq-platform/#via-metriq-api","title":"Via Metriq API","text":"<p>The Metriq platform provides an API for programmatic access:</p> <pre><code># Get your API key at https://metriq.info/Token\nexport METRIQ_CLIENT_API_KEY=\"your-key\"\n</code></pre>"},{"location":"getting-started/metriq-platform/#community-and-support","title":"Community and Support","text":"<ul> <li>Report issues: metriq-gym issues</li> <li>Data questions: metriq-data discussions</li> <li>Platform feedback: Contact the Unitary Foundation team</li> </ul>"},{"location":"getting-started/metriq-platform/#related-links","title":"Related Links","text":"<ul> <li>Metriq Platform</li> <li>metriq-data Repository</li> <li>Unitary Foundation</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quickstart","text":"<p>Metriq-Gym provides a command-line interface for running quantum benchmark jobs on simulators and hardware. This guide focuses on the essentials so you can submit your first job quickly.</p>"},{"location":"getting-started/quickstart/#installation","title":"Installation","text":"<p>Install the package from PyPI:</p> <pre><code>pip install metriq-gym\n</code></pre>"},{"location":"getting-started/quickstart/#running-your-first-benchmark","title":"Running Your First Benchmark","text":""},{"location":"getting-started/quickstart/#1-download-an-example-configuration","title":"1. Download an Example Configuration","text":"<p>Download an example configuration file for the WIT (Wormhole-inspired teleportation) benchmark:</p> <pre><code>curl -O https://raw.githubusercontent.com/unitaryfoundation/metriq-gym/main/metriq_gym/schemas/examples/wit.example.json\n</code></pre> <p>Note</p> <p>Example configurations for all benchmarks are available in the <code>metriq_gym/schemas/examples/</code> directory.</p>"},{"location":"getting-started/quickstart/#2-dispatch-the-benchmark","title":"2. Dispatch the Benchmark","text":"<p>Run the benchmark on the local Aer simulator:</p> <pre><code>mgym job dispatch wit.example.json -p local -d aer_simulator\n</code></pre> <p>This command dispatches the job and returns a job ID that you'll use to check results.</p>"},{"location":"getting-started/quickstart/#3-poll-for-results","title":"3. Poll for Results","text":"<p>Check the status and retrieve results:</p> <pre><code>mgym job poll latest\n</code></pre> <p>If the job completed, metrics such as expectation values are reported in your terminal.</p> <p>Tip</p> <p>Use <code>mgym job poll</code> without arguments to choose from recent jobs interactively.</p>"},{"location":"getting-started/quickstart/#configuration-files","title":"Configuration Files","text":"<p>Each benchmark is configured via JSON documents. The <code>metriq_gym/schemas/examples/</code> directory contains ready-to-run templates for all supported benchmarks. Customize a copy to:</p> <ul> <li>Switch benchmarks (change <code>benchmark_name</code>)</li> <li>Adjust qubit counts or shots</li> <li>Supply provider-specific options</li> </ul> <p>Example WIT configuration:</p> <pre><code>{\n  \"benchmark_name\": \"WIT\",\n  \"num_qubits\": 7,\n  \"shots\": 8192\n}\n</code></pre>"},{"location":"getting-started/quickstart/#running-on-real-hardware","title":"Running on Real Hardware","text":"<p>To run benchmarks on cloud quantum hardware:</p> <ol> <li>Set up provider credentials in a <code>.env</code> file (see Provider Configuration)</li> <li>Specify the provider and device:</li> </ol> <pre><code>mgym job dispatch wit.example.json --provider ibm --device ibm_fez\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>End-to-End Tutorial - Complete walkthrough including uploading results</li> <li>CLI Reference - All available commands</li> <li>Provider Configuration - Setup guides for each provider</li> <li>Benchmarks - Available benchmarks and their configurations</li> </ul>"},{"location":"getting-started/tutorial/","title":"End-to-End Tutorial","text":"<p>This tutorial provides a comprehensive walkthrough of using Metriq-Gym, from dispatching benchmarks to uploading results to the Metriq platform.</p>"},{"location":"getting-started/tutorial/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have:</p> <ul> <li>Metriq-Gym installed (<code>pip install metriq-gym</code>)</li> <li>A <code>.env</code> file with provider credentials (see Provider Configuration)</li> </ul>"},{"location":"getting-started/tutorial/#setup","title":"Setup","text":"<p>First, load environment variables in your Python session:</p> <pre><code>from types import SimpleNamespace\nfrom dotenv import load_dotenv\nfrom metriq_gym.run import dispatch_job, poll_job, view_job, upload_job\nfrom metriq_gym.job_manager import JobManager\n\n# Load environment variables from .env file\nload_dotenv()\n</code></pre>"},{"location":"getting-started/tutorial/#job-handling","title":"Job Handling","text":"<p>Metriq-Gym provides a simple API to dispatch jobs to quantum devices and poll/view their status.</p>"},{"location":"getting-started/tutorial/#dispatching-a-job","title":"Dispatching a Job","text":"<p>Use the Python interface to dispatch a job to a quantum device or local simulator:</p> <pre><code>job_manager = JobManager()\nbenchmark_path = \"metriq_gym/schemas/examples/wit.example.json\"\nprovider_name = \"local\"\ndevice_name = \"aer_simulator\"\n\ndispatch_config = SimpleNamespace(\n    config=benchmark_path,\n    provider=provider_name,\n    device=device_name,\n)\n\ndispatch_job(dispatch_config, job_manager)\n</code></pre> <p>Output: <pre><code>Starting dispatch on local:aer_simulator...\nDispatching WIT...\nJob dispatched with metriq-gym Job ID: 7cb5b2df-e62d-423f-ac22-4bf6739d2ea4\n</code></pre></p> <p>Dispatching creates a local <code>.jsonl</code> file that tracks all job metadata.</p>"},{"location":"getting-started/tutorial/#viewing-job-details","title":"Viewing Job Details","text":"<p>Check job metadata before polling:</p> <pre><code>jobs = job_manager.get_jobs()\njob_id_to_poll = jobs[-1].id\n\njob_config = SimpleNamespace(job_id=job_id_to_poll)\nview_job(job_config, job_manager)\n</code></pre> <p>This displays a table with job details including provider, device, parameters, and dispatch time.</p>"},{"location":"getting-started/tutorial/#polling-for-results","title":"Polling for Results","text":"<p>Poll the job to retrieve results:</p> <pre><code>poll_job(job_config, job_manager)\n</code></pre> <p>Output: <pre><code>{\n    'app_version': '0.3.1',\n    'device': 'aer_simulator',\n    'job_type': 'WIT',\n    'provider': 'local',\n    'results': {'expectation_value': 0.9970703125},\n    'suite_id': None,\n    'timestamp': '2025-01-15T09:54:47.904520'\n}\n</code></pre></p> <p>For the WIT benchmark, the ideal expectation value is <code>1.0</code>. The simulated result of <code>~0.997</code> is very close, indicating correct circuit execution.</p>"},{"location":"getting-started/tutorial/#uploading-results","title":"Uploading Results","text":"<p>After polling your job and verifying the results, you can upload them to the Metriq platform via GitHub.</p>"},{"location":"getting-started/tutorial/#prerequisites_1","title":"Prerequisites","text":"<p>Set up a GitHub token with repository permissions:</p> <pre><code>export GITHUB_TOKEN=\"your-token-here\"\n</code></pre> <p>Creating a GitHub Token</p> <p>Create a Personal Access Token at github.com/settings/tokens with repository read/write permissions.</p>"},{"location":"getting-started/tutorial/#upload-via-python","title":"Upload via Python","text":"<pre><code>from types import SimpleNamespace\nfrom metriq_gym.run import upload_job\n\nupload_config = SimpleNamespace(\n    job_id=job_id_to_poll,\n    repo=\"unitaryfoundation/metriq-data\",  # default repository\n    dir=None,  # uses default: metriq-gym/v&lt;version&gt;/&lt;provider&gt;/&lt;device&gt;\n)\n\nupload_job(upload_config, job_manager)\n</code></pre>"},{"location":"getting-started/tutorial/#upload-via-cli","title":"Upload via CLI","text":"<pre><code>mgym job upload &lt;METRIQ_GYM_JOB_ID&gt;\n</code></pre> <p>This creates a pull request to <code>unitaryfoundation/metriq-data</code> containing your benchmark results. Once merged, results appear on metriq.info.</p>"},{"location":"getting-started/tutorial/#upload-configuration","title":"Upload Configuration","text":"<p>You can customize the upload destination:</p> Option Environment Variable Default Target repository <code>MGYM_UPLOAD_REPO</code> <code>unitaryfoundation/metriq-data</code> Base branch <code>MGYM_UPLOAD_BASE_BRANCH</code> <code>main</code> Upload directory <code>MGYM_UPLOAD_DIR</code> <code>metriq-gym/v&lt;major.minor&gt;/&lt;provider&gt;/&lt;device&gt;</code>"},{"location":"getting-started/tutorial/#cli-equivalents","title":"CLI Equivalents","text":"<p>All operations above can also be performed via the CLI:</p> <pre><code># Dispatch\nmgym job dispatch metriq_gym/schemas/examples/wit.example.json \\\n    --provider local --device aer_simulator\n\n# View\nmgym job view &lt;JOB_ID&gt;\n\n# Poll\nmgym job poll &lt;JOB_ID&gt;\n\n# Upload\nmgym job upload &lt;JOB_ID&gt;\n</code></pre> <p>Use <code>mgym job poll</code> or <code>mgym job view</code> without arguments to interactively select a job.</p>"},{"location":"getting-started/tutorial/#running-on-real-hardware","title":"Running on Real Hardware","text":"<p>To run benchmarks on IBM Quantum hardware:</p> <pre><code>dispatch_config = SimpleNamespace(\n    config=\"metriq_gym/schemas/examples/wit.example.json\",\n    provider=\"ibm\",\n    device=\"ibm_fez\",\n)\n\ndispatch_job(dispatch_config, job_manager)\n</code></pre> <p>Note</p> <p>Hardware jobs may be queued. Poll periodically to check status and retrieve results when complete.</p>"},{"location":"getting-started/tutorial/#next-steps","title":"Next Steps","text":"<ul> <li>CLI Reference - Detailed command documentation</li> <li>Provider Configuration - Setup guides for all providers</li> <li>Benchmarks - Available benchmarks</li> <li>Metriq Platform - How results appear on metriq.info</li> </ul>"},{"location":"providers/azure/","title":"Azure Quantum","text":"<p>Run benchmarks on quantum computers through Microsoft Azure Quantum.</p>"},{"location":"providers/azure/#prerequisites","title":"Prerequisites","text":"<ul> <li>An Azure account</li> <li>An Azure Quantum workspace</li> <li>Azure Quantum connection string</li> </ul>"},{"location":"providers/azure/#setup","title":"Setup","text":""},{"location":"providers/azure/#1-create-an-azure-quantum-workspace","title":"1. Create an Azure Quantum Workspace","text":"<ol> <li>Log in to the Azure Portal</li> <li>Create a new Azure Quantum workspace</li> <li>Add providers (IonQ, Quantinuum, Rigetti, etc.) to your workspace</li> </ol>"},{"location":"providers/azure/#2-get-connection-string","title":"2. Get Connection String","text":"<ol> <li>Navigate to your Azure Quantum workspace</li> <li>Go to Overview &gt; Connection string</li> <li>Copy the connection string</li> </ol>"},{"location":"providers/azure/#3-configure-environment","title":"3. Configure Environment","text":"<p>Add to your <code>.env</code> file:</p> <pre><code>AZURE_QUANTUM_CONNECTION_STRING=\"&lt;your-connection-string&gt;\"\n</code></pre> <p>The connection string format is: <pre><code>SubscriptionId=xxx;ResourceGroupName=xxx;WorkspaceName=xxx;Location=xxx\n</code></pre></p>"},{"location":"providers/azure/#discovering-devices","title":"Discovering Devices","text":"<p>Azure Quantum provides access to multiple hardware providers (IonQ, Quantinuum, Rigetti). Available devices depend on your workspace configuration.</p> <p>To see currently available devices:</p> <pre><code>from qbraid.runtime import load_provider\n\nprovider = load_provider(\"azure\")\nfor device in provider.get_devices():\n    print(f\"{device.id}: {device.status}\")\n</code></pre> <p>Or check your workspace in the Azure Portal under Providers.</p> <p>Note</p> <p>Enable providers in your Azure Quantum workspace to access their devices.</p>"},{"location":"providers/azure/#usage","title":"Usage","text":""},{"location":"providers/azure/#dispatch-to-azure-quantum-hardware","title":"Dispatch to Azure Quantum Hardware","text":"<pre><code>mgym job dispatch metriq_gym/schemas/examples/wit.example.json \\\n    --provider azure --device ionq.qpu.aria-1\n</code></pre>"},{"location":"providers/azure/#dispatch-to-azure-quantum-simulator","title":"Dispatch to Azure Quantum Simulator","text":"<pre><code>mgym job dispatch metriq_gym/schemas/examples/wit.example.json \\\n    --provider azure --device ionq.simulator\n</code></pre>"},{"location":"providers/azure/#poll-results","title":"Poll Results","text":"<pre><code>mgym job poll &lt;JOB_ID&gt;\n</code></pre>"},{"location":"providers/azure/#pricing","title":"Pricing","text":"<p>See Azure Quantum Pricing for current rates.</p>"},{"location":"providers/azure/#troubleshooting","title":"Troubleshooting","text":""},{"location":"providers/azure/#connection-errors","title":"Connection Errors","text":"<p>Verify your connection string:</p> <pre><code>from azure.quantum import Workspace\n\nworkspace = Workspace(\n    subscription_id=\"...\",\n    resource_group=\"...\",\n    name=\"...\",\n    location=\"...\"\n)\nprint(workspace.get_targets())\n</code></pre>"},{"location":"providers/azure/#provider-not-available","title":"Provider Not Available","text":"<p>Ensure the provider is:</p> <ol> <li>Enabled in your workspace</li> <li>Available in your region</li> <li>Accessible with your subscription tier</li> </ol>"},{"location":"providers/azure/#job-failures","title":"Job Failures","text":"<p>Check job status in the Azure Portal under your workspace's Job management section for detailed error messages.</p>"},{"location":"providers/braket/","title":"AWS Braket","text":"<p>Run benchmarks on quantum computers through Amazon Braket.</p>"},{"location":"providers/braket/#prerequisites","title":"Prerequisites","text":"<ul> <li>An AWS account</li> <li>AWS credentials with Braket permissions</li> <li>(Optional) An S3 bucket for job results</li> </ul>"},{"location":"providers/braket/#setup","title":"Setup","text":""},{"location":"providers/braket/#1-get-aws-credentials","title":"1. Get AWS Credentials","text":"<ol> <li>Log in to the AWS Console</li> <li>Navigate to IAM &gt; Users &gt; Your User &gt; Security credentials</li> <li>Create an access key</li> </ol>"},{"location":"providers/braket/#2-configure-environment","title":"2. Configure Environment","text":"<p>Add to your <code>.env</code> file:</p> <pre><code>AWS_ACCESS_KEY_ID=\"&lt;your-access-key&gt;\"\nAWS_SECRET_ACCESS_KEY=\"&lt;your-secret-key&gt;\"\n</code></pre> <p>Optionally, set your default region:</p> <pre><code>AWS_DEFAULT_REGION=\"us-east-1\"\n</code></pre>"},{"location":"providers/braket/#discovering-devices","title":"Discovering Devices","text":"<p>AWS Braket provides access to multiple hardware providers (IonQ, Rigetti, IQM) and simulators. Device availability changes frequently.</p> <p>To see currently available devices:</p> <pre><code>from qbraid.runtime import load_provider\n\nprovider = load_provider(\"braket\")\nfor device in provider.get_devices():\n    print(f\"{device.id}: {device.status}\")\n</code></pre> <p>Or check the Braket Console for current devices and their ARNs.</p>"},{"location":"providers/braket/#usage","title":"Usage","text":""},{"location":"providers/braket/#dispatch-to-braket-hardware","title":"Dispatch to Braket Hardware","text":"<pre><code>mgym job dispatch metriq_gym/schemas/examples/wit.example.json \\\n    --provider braket \\\n    --device \"arn:aws:braket:us-east-1::device/qpu/ionq/Aria-1\"\n</code></pre>"},{"location":"providers/braket/#dispatch-to-braket-simulator","title":"Dispatch to Braket Simulator","text":"<pre><code>mgym job dispatch metriq_gym/schemas/examples/wit.example.json \\\n    --provider braket \\\n    --device \"arn:aws:braket:::device/quantum-simulator/amazon/sv1\"\n</code></pre>"},{"location":"providers/braket/#poll-results","title":"Poll Results","text":"<pre><code>mgym job poll &lt;JOB_ID&gt;\n</code></pre>"},{"location":"providers/braket/#pricing","title":"Pricing","text":"<p>See AWS Braket Pricing for current rates.</p>"},{"location":"providers/braket/#troubleshooting","title":"Troubleshooting","text":""},{"location":"providers/braket/#authentication-errors","title":"Authentication Errors","text":"<p>Verify credentials:</p> <pre><code>import boto3\nclient = boto3.client('braket')\nprint(client.search_devices(filters=[]))\n</code></pre>"},{"location":"providers/braket/#region-issues","title":"Region Issues","text":"<p>Some devices are only available in specific regions. Ensure your <code>AWS_DEFAULT_REGION</code> matches the device location.</p>"},{"location":"providers/braket/#insufficient-permissions","title":"Insufficient Permissions","text":"<p>Your IAM user/role needs the <code>AmazonBraketFullAccess</code> policy or equivalent permissions.</p>"},{"location":"providers/ibm/","title":"IBM Quantum","text":"<p>Run benchmarks on IBM Quantum hardware through the IBM Quantum Platform.</p>"},{"location":"providers/ibm/#prerequisites","title":"Prerequisites","text":"<ul> <li>An IBM Quantum account</li> <li>An IBM Cloud API key</li> </ul>"},{"location":"providers/ibm/#setup","title":"Setup","text":""},{"location":"providers/ibm/#1-get-your-api-key","title":"1. Get Your API Key","text":"<ol> <li>Log in to IBM Cloud</li> <li>Navigate to Manage &gt; Access (IAM) &gt; API keys</li> <li>Create a new API key or use an existing one</li> </ol>"},{"location":"providers/ibm/#2-configure-environment","title":"2. Configure Environment","text":"<p>Add to your <code>.env</code> file:</p> <pre><code># Required\nQISKIT_IBM_TOKEN=\"&lt;your-ibm-cloud-api-key&gt;\"\n\n# Optional\nQISKIT_IBM_CHANNEL=\"ibm_quantum_platform\"  # or \"ibm_quantum\"\nQISKIT_IBM_INSTANCE=\"&lt;instance-crn&gt;\"       # for specific instance access\n</code></pre>"},{"location":"providers/ibm/#discovering-devices","title":"Discovering Devices","text":"<p>Device availability depends on your IBM Quantum plan and changes frequently. To see your available devices:</p> <pre><code>from qbraid.runtime import load_provider\n\nprovider = load_provider(\"ibm\")\nfor device in provider.get_devices():\n    print(f\"{device.id}: {device.num_qubits} qubits - {device.status}\")\n</code></pre> <p>Or visit quantum.ibm.com to check your dashboard.</p>"},{"location":"providers/ibm/#usage","title":"Usage","text":""},{"location":"providers/ibm/#dispatch-to-ibm-hardware","title":"Dispatch to IBM Hardware","text":"<pre><code>mgym job dispatch metriq_gym/schemas/examples/bseq.example.json \\\n    --provider ibm --device ibm_sherbrooke\n</code></pre>"},{"location":"providers/ibm/#example-output","title":"Example Output","text":"<pre><code>Starting dispatch on ibm:ibm_sherbrooke...\nDispatching BSEQ benchmark from bseq.example.json on ibm_sherbrooke...\nJob dispatched with ID: 93a06a18-41d8-475a-a030-339fbf3accb9\n</code></pre>"},{"location":"providers/ibm/#poll-results","title":"Poll Results","text":"<pre><code>mgym job poll 93a06a18-41d8-475a-a030-339fbf3accb9\n</code></pre> <p>If the job is queued: <pre><code>Job is queued at position 5. Please try again later.\n</code></pre></p> <p>When complete: <pre><code>BSEQResult(largest_connected_size=100, fraction_connected=0.7874)\n</code></pre></p>"},{"location":"providers/ibm/#noise-model-simulation","title":"Noise Model Simulation","text":"<p>Run benchmarks locally with IBM device noise models:</p> <pre><code>mgym job dispatch config.json --provider local --device ibm_sherbrooke\n</code></pre> <p>This uses Qiskit Aer with the noise model from the specified IBM device.</p>"},{"location":"providers/ibm/#resource-estimation","title":"Resource Estimation","text":"<p>Estimate job resources before dispatch:</p> <pre><code>mgym job estimate metriq_gym/schemas/examples/bseq.example.json \\\n    --provider ibm --device ibm_fez\n</code></pre>"},{"location":"providers/ibm/#troubleshooting","title":"Troubleshooting","text":""},{"location":"providers/ibm/#authentication-errors","title":"Authentication Errors","text":"<p>Ensure your API key is valid and has appropriate permissions:</p> <pre><code>from qiskit_ibm_runtime import QiskitRuntimeService\nservice = QiskitRuntimeService(channel=\"ibm_quantum_platform\")\nprint(service.backends())\n</code></pre>"},{"location":"providers/ibm/#device-unavailable","title":"Device Unavailable","text":"<p>Check device status on the IBM Quantum Platform. Devices may be: - Under maintenance - Reserved for specific access levels - Temporarily offline</p>"},{"location":"providers/ibm/#queue-times","title":"Queue Times","text":"<p>IBM Quantum jobs may experience long queue times during peak usage. Consider: - Using simulators for development - Scheduling jobs during off-peak hours - Using fair-share queuing through instance selection</p>"},{"location":"providers/ionq/","title":"IonQ","text":"<p>Run benchmarks on IonQ trapped-ion quantum computers.</p>"},{"location":"providers/ionq/#prerequisites","title":"Prerequisites","text":"<ul> <li>An IonQ account</li> <li>An IonQ API key</li> </ul>"},{"location":"providers/ionq/#setup","title":"Setup","text":""},{"location":"providers/ionq/#1-get-your-api-key","title":"1. Get Your API Key","text":"<ol> <li>Log in to IonQ Cloud</li> <li>Navigate to Settings &gt; API Keys</li> <li>Create a new API key</li> </ol>"},{"location":"providers/ionq/#2-configure-environment","title":"2. Configure Environment","text":"<p>Add to your <code>.env</code> file:</p> <pre><code>IONQ_API_KEY=\"&lt;your-ionq-api-key&gt;\"\n</code></pre>"},{"location":"providers/ionq/#discovering-devices","title":"Discovering Devices","text":"<p>Device availability changes frequently. To see currently available devices:</p> <pre><code>from qbraid.runtime import load_provider\n\nprovider = load_provider(\"ionq\")\nfor device in provider.get_devices():\n    print(f\"{device.id}: {device.num_qubits} qubits - {device.status}\")\n</code></pre> <p>Or check the IonQ Cloud dashboard for current device status.</p>"},{"location":"providers/ionq/#usage","title":"Usage","text":""},{"location":"providers/ionq/#dispatch-to-ionq-hardware","title":"Dispatch to IonQ Hardware","text":"<pre><code>mgym job dispatch metriq_gym/schemas/examples/wit.example.json \\\n    --provider ionq --device ionq_aria\n</code></pre>"},{"location":"providers/ionq/#dispatch-to-ionq-simulator","title":"Dispatch to IonQ Simulator","text":"<pre><code>mgym job dispatch metriq_gym/schemas/examples/wit.example.json \\\n    --provider ionq --device ionq_simulator\n</code></pre>"},{"location":"providers/ionq/#poll-results","title":"Poll Results","text":"<pre><code>mgym job poll &lt;JOB_ID&gt;\n</code></pre>"},{"location":"providers/ionq/#ionq-specific-considerations","title":"IonQ-Specific Considerations","text":""},{"location":"providers/ionq/#native-gate-set","title":"Native Gate Set","text":"<p>IonQ uses a native gate set of single-qubit rotations and the MS (Molmer-Sorensen) two-qubit gate. Circuits are automatically transpiled.</p>"},{"location":"providers/ionq/#debiasing","title":"Debiasing","text":"<p>IonQ supports debiasing options for error mitigation. Configure via provider settings if available.</p>"},{"location":"providers/ionq/#pricing","title":"Pricing","text":"<p>See IonQ Pricing for current rates.</p>"},{"location":"providers/ionq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"providers/ionq/#authentication-errors","title":"Authentication Errors","text":"<p>Verify your API key:</p> <pre><code>import os\nos.environ[\"IONQ_API_KEY\"] = \"your-key\"\n\nfrom qbraid.runtime import load_provider\nprovider = load_provider(\"ionq\")\nprint(provider.get_devices())\n</code></pre>"},{"location":"providers/ionq/#device-unavailable","title":"Device Unavailable","text":"<p>Check device status on the IonQ Cloud dashboard. Devices may be under maintenance.</p>"},{"location":"providers/local/","title":"Local Simulators","text":"<p>Run benchmarks locally using Qiskit Aer simulators. This is useful for development, testing, and running benchmarks without cloud access.</p>"},{"location":"providers/local/#prerequisites","title":"Prerequisites","text":"<p>No additional setup required - Qiskit Aer is included with Metriq-Gym.</p>"},{"location":"providers/local/#discovering-devices","title":"Discovering Devices","text":"<p>To see available local simulators:</p> <pre><code>from qbraid.runtime import load_provider\n\nprovider = load_provider(\"local\")\nfor device in provider.get_devices():\n    print(f\"{device.id}\")\n</code></pre> <p>Common simulators include:</p> <ul> <li><code>aer_simulator</code> - Ideal state vector simulation</li> <li><code>aer_simulator_statevector</code> - State vector simulator (explicit)</li> <li><code>aer_simulator_density_matrix</code> - Density matrix simulator</li> </ul>"},{"location":"providers/local/#ibm-noise-model-simulators","title":"IBM Noise Model Simulators","text":"<p>Use any IBM device name (e.g., <code>ibm_sherbrooke</code>, <code>ibm_fez</code>) to run locally with that device's noise model.</p> <p>Note</p> <p>Noise model simulators require valid IBM credentials to fetch the noise model, but execution is local.</p>"},{"location":"providers/local/#usage","title":"Usage","text":""},{"location":"providers/local/#ideal-simulation","title":"Ideal Simulation","text":"<pre><code>mgym job dispatch metriq_gym/schemas/examples/wit.example.json \\\n    --provider local --device aer_simulator\n</code></pre>"},{"location":"providers/local/#noisy-simulation","title":"Noisy Simulation","text":"<pre><code>mgym job dispatch metriq_gym/schemas/examples/wit.example.json \\\n    --provider local --device ibm_sherbrooke\n</code></pre>"},{"location":"providers/local/#poll-results","title":"Poll Results","text":"<pre><code>mgym job poll &lt;JOB_ID&gt;\n</code></pre> <p>Local jobs complete immediately, so polling returns results instantly.</p>"},{"location":"providers/local/#configuration","title":"Configuration","text":""},{"location":"providers/local/#cache-directory","title":"Cache Directory","text":"<p>Control where simulator results are cached:</p> <pre><code># In .env\nMGYM_LOCAL_SIMULATOR_CACHE_DIR=\"/path/to/cache\"\n</code></pre> <p>Default: Platform-specific cache directory (e.g., <code>~/Library/Caches/metriq-gym</code> on macOS)</p>"},{"location":"providers/local/#use-cases","title":"Use Cases","text":""},{"location":"providers/local/#development-and-testing","title":"Development and Testing","text":"<p>Test benchmark configurations before running on hardware:</p> <pre><code># Quick validation\nmgym job dispatch new_config.json -p local -d aer_simulator\nmgym job poll latest\n</code></pre>"},{"location":"providers/local/#benchmarking-simulators","title":"Benchmarking Simulators","text":"<p>Compare ideal vs. noisy simulation:</p> <pre><code># Ideal\nmgym job dispatch wit.example.json -p local -d aer_simulator\n\n# With noise\nmgym job dispatch wit.example.json -p local -d ibm_sherbrooke\n</code></pre>"},{"location":"providers/local/#large-scale-simulations","title":"Large-Scale Simulations","text":"<p>For benchmarks requiring many qubits:</p> <pre><code># Use density matrix for mixed states\nmgym job dispatch config.json -p local -d aer_simulator_density_matrix\n</code></pre>"},{"location":"providers/local/#performance-considerations","title":"Performance Considerations","text":""},{"location":"providers/local/#memory-usage","title":"Memory Usage","text":"<p>State vector simulation requires <code>2^n * 16</code> bytes of memory for <code>n</code> qubits:</p> Qubits Memory 20 ~16 MB 25 ~512 MB 30 ~16 GB 35 ~512 GB"},{"location":"providers/local/#gpu-acceleration","title":"GPU Acceleration","text":"<p>Aer supports GPU acceleration via CUDA. If available, simulations automatically use the GPU.</p>"},{"location":"providers/local/#parallelization","title":"Parallelization","text":"<p>For benchmarks with multiple circuits, Aer parallelizes across available CPU cores.</p>"},{"location":"providers/local/#noise-model-details","title":"Noise Model Details","text":"<p>When using <code>ibm_&lt;device&gt;</code> noise models:</p> <ol> <li>Metriq-Gym fetches the current noise model from IBM Quantum</li> <li>The model includes:</li> <li>Single-qubit gate errors</li> <li>Two-qubit gate errors</li> <li>Readout errors</li> <li>T1/T2 decoherence</li> <li>Circuits are transpiled to the device's basis gates</li> <li>Simulation runs locally with the noise model applied</li> </ol>"},{"location":"providers/local/#noise-model-caching","title":"Noise Model Caching","text":"<p>Noise models are cached to reduce API calls. Clear the cache by deleting:</p> <pre><code>rm -rf $MGYM_LOCAL_SIMULATOR_CACHE_DIR\n</code></pre>"},{"location":"providers/local/#troubleshooting","title":"Troubleshooting","text":""},{"location":"providers/local/#out-of-memory","title":"Out of Memory","text":"<p>Reduce qubit count or use a more efficient simulation method:</p> <pre><code># For specific amplitude calculations\nmgym job dispatch config.json -p local -d aer_simulator_statevector\n</code></pre>"},{"location":"providers/local/#slow-simulation","title":"Slow Simulation","text":"<p>For deep circuits: - Reduce shot count for testing - Use ideal simulation without noise models - Consider cloud hardware for production runs</p>"},{"location":"providers/originq/","title":"OriginQ (Wukong)","text":"<p>Run benchmarks on OriginQ Wukong superconducting quantum computers.</p>"},{"location":"providers/originq/#prerequisites","title":"Prerequisites","text":"<ul> <li>An OriginQ QCloud account</li> <li>OriginQ API token</li> <li>(macOS only) <code>libidn2</code> library</li> </ul>"},{"location":"providers/originq/#setup","title":"Setup","text":""},{"location":"providers/originq/#1-get-your-api-token","title":"1. Get Your API Token","text":"<ol> <li>Log in to the OriginQ Workbench</li> <li>Navigate to your account settings</li> <li>Copy your API token</li> </ol>"},{"location":"providers/originq/#2-configure-environment","title":"2. Configure Environment","text":"<p>Add to your <code>.env</code> file:</p> <pre><code>ORIGIN_API_KEY=\"&lt;your-origin-api-token&gt;\"\n</code></pre>"},{"location":"providers/originq/#3-macos-setup","title":"3. macOS Setup","text":"<p>macOS users must install <code>libidn2</code> before using the OriginQ provider:</p> <pre><code>brew reinstall libidn2\n</code></pre> <p>Install this library before running <code>uv sync</code> or installing Metriq-Gym to avoid missing symbol errors during the <code>pyqpanda3</code> build.</p>"},{"location":"providers/originq/#discovering-devices","title":"Discovering Devices","text":"<p>To see currently available devices:</p> <pre><code>from qbraid.runtime import load_provider\n\nprovider = load_provider(\"origin\")\nfor device in provider.get_devices():\n    print(f\"{device.id}: {device.status}\")\n</code></pre> <p>OriginQ offers both hardware (including the Wukong quantum computer) and various simulators.</p>"},{"location":"providers/originq/#usage","title":"Usage","text":""},{"location":"providers/originq/#dispatch-to-wukong-hardware","title":"Dispatch to Wukong Hardware","text":"<pre><code># Using alias\nmgym job dispatch metriq_gym/schemas/examples/wit.example.json \\\n    --provider origin --device origin_wukong\n\n# Using numeric ID\nmgym job dispatch metriq_gym/schemas/examples/wit.example.json \\\n    --provider origin --device 72\n</code></pre>"},{"location":"providers/originq/#dispatch-to-originq-simulator","title":"Dispatch to OriginQ Simulator","text":"<pre><code>mgym job dispatch metriq_gym/schemas/examples/wit.example.json \\\n    --provider origin --device full_amplitude\n</code></pre>"},{"location":"providers/originq/#poll-results","title":"Poll Results","text":"<pre><code>mgym job poll &lt;JOB_ID&gt;\n</code></pre>"},{"location":"providers/originq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"providers/originq/#resource-is-null-error","title":"\"resource is null\" Error","text":"<p>This error indicates: - The device name is incorrect - Your account lacks permission for the requested device</p> <p>Verify available devices with the listing command above.</p>"},{"location":"providers/originq/#missing-libidn2-macos","title":"Missing libidn2 (macOS)","text":"<p>If you see symbol errors related to <code>pyqpanda3</code>:</p> <pre><code># Install the library\nbrew reinstall libidn2\n\n# Reinstall metriq-gym\npip install --force-reinstall metriq-gym\n</code></pre>"},{"location":"providers/originq/#authentication-errors","title":"Authentication Errors","text":"<p>Verify your API token is correctly set:</p> <pre><code>import os\nprint(os.environ.get(\"ORIGIN_API_KEY\"))\n</code></pre>"},{"location":"providers/originq/#connection-issues","title":"Connection Issues","text":"<p>OriginQ services are based in China. Connection latency or timeouts may occur from other regions. Consider: - Retrying failed requests - Using longer timeout values - Running during off-peak hours</p>"},{"location":"providers/originq/#device-topology","title":"Device Topology","text":"<p>Wukong devices use a 2D grid topology. For topology-dependent benchmarks (BSEQ, Mirror Circuits), the provider automatically retrieves connectivity information.</p> <pre><code>from metriq_gym.run import load_provider\n\nprovider = load_provider('origin')\ndevice = provider.get_device('origin_wukong')\n# Topology available via device.metadata\n</code></pre>"},{"location":"providers/overview/","title":"Provider Configuration","text":"<p>Metriq-Gym supports multiple quantum hardware providers through a unified interface built on qBraid Runtime.</p>"},{"location":"providers/overview/#why-qbraid","title":"Why qBraid?","text":"<p>We chose qBraid Runtime as our provider abstraction layer for several reasons:</p> <ul> <li>Unified interface: qBraid provides consistent APIs for common device operations (transpilation, job submission, result retrieval) across different providers, reducing provider-specific code paths that could introduce variability in benchmark execution.</li> <li>Extensibility: The provider interface is straightforward to extend. We've used it to add support for providers that qBraid doesn't natively support, including OriginQ and Quantinuum (via NEXUS).</li> <li>Transpilation consistency: Using a common transpilation pipeline helps ensure that circuit transformations are applied consistently across providers, which is important for fair benchmark comparisons.</li> </ul> <p>Note that benchmarks executed through qBraid may differ slightly from those run through native provider SDKs due to differences in transpilation strategies or default settings. For reproducibility, Metriq-Gym records the software versions and configuration used for each benchmark run.</p>"},{"location":"providers/overview/#supported-providers","title":"Supported Providers","text":"Provider Provider ID Description IBM Quantum <code>ibm</code> IBM's quantum computers and simulators IonQ <code>ionq</code> IonQ trapped-ion quantum computers AWS Braket <code>braket</code> Amazon Braket quantum computing service Azure Quantum <code>azure</code> Microsoft Azure Quantum Quantinuum <code>quantinuum</code> Quantinuum H-series trapped-ion systems OriginQ <code>origin</code> OriginQ Wukong superconducting systems Local Simulators <code>local</code> Qiskit Aer local simulation"},{"location":"providers/overview/#provider-architecture","title":"Provider Architecture","text":"<p>Metriq-Gym uses two types of provider integrations:</p>"},{"location":"providers/overview/#qbraid-managed-providers","title":"qBraid-Managed Providers","text":"<p>IBM, IonQ, Braket, and Azure use qBraid Runtime's native provider support:</p> <pre><code>from qbraid.runtime import load_provider\nprovider = load_provider(\"ibm\")\n</code></pre>"},{"location":"providers/overview/#custom-providers","title":"Custom Providers","text":"<p>Local, Quantinuum (NEXUS), and OriginQ use custom provider implementations registered via entry points:</p> <pre><code># Registered in pyproject.toml\n[project.entry-points.\"qbraid.providers\"]\nlocal = \"metriq_gym.local.provider:LocalProvider\"\nquantinuum = \"metriq_gym.quantinuum.provider:QuantinuumProvider\"\norigin = \"metriq_gym.origin.provider:OriginProvider\"\n</code></pre>"},{"location":"providers/overview/#credential-configuration","title":"Credential Configuration","text":"<p>Create a <code>.env</code> file in your project root with provider credentials:</p> <pre><code># Copy the template\ncp .env.example .env\n\n# Edit with your credentials\nnano .env\n</code></pre> <p>Protect your credentials</p> <p>Your <code>.env</code> file contains sensitive API keys and tokens. Ensure it is listed in your <code>.gitignore</code> to avoid accidentally committing secrets to version control. Never share or publish this file.</p>"},{"location":"providers/overview/#environment-variables-reference","title":"Environment Variables Reference","text":"Variable Provider Description <code>QISKIT_IBM_TOKEN</code> IBM IBM Cloud API key <code>QISKIT_IBM_CHANNEL</code> IBM Channel type (optional) <code>QISKIT_IBM_INSTANCE</code> IBM Instance CRN (optional) <code>IONQ_API_KEY</code> IonQ IonQ API key <code>AWS_ACCESS_KEY_ID</code> Braket AWS access key <code>AWS_SECRET_ACCESS_KEY</code> Braket AWS secret key <code>AZURE_QUANTUM_CONNECTION_STRING</code> Azure Azure connection string <code>QUANTINUUM_NEXUS_USERNAME</code> Quantinuum NEXUS username <code>QUANTINUUM_NEXUS_PASSWORD</code> Quantinuum NEXUS password <code>ORIGIN_API_KEY</code> OriginQ OriginQ API token"},{"location":"providers/overview/#device-selection","title":"Device Selection","text":"<p>List available devices for a provider:</p> <pre><code>from metriq_gym.run import load_provider\n\nprovider = load_provider(\"ibm\")\ndevices = provider.get_devices()\nfor device in devices:\n    print(f\"{device.id}: {device.status}\")\n</code></pre> <p>Via CLI, use provider-specific documentation to find device names.</p>"},{"location":"providers/overview/#next-steps","title":"Next Steps","text":"<ul> <li>IBM Quantum - IBM Quantum Platform setup</li> <li>IonQ - IonQ Cloud setup</li> <li>AWS Braket - Amazon Braket setup</li> <li>Azure Quantum - Azure Quantum setup</li> <li>Quantinuum - Quantinuum NEXUS setup</li> <li>OriginQ - OriginQ Wukong setup</li> <li>Local Simulators - Running benchmarks locally</li> </ul>"},{"location":"providers/quantinuum/","title":"Quantinuum","text":"<p>Run benchmarks on Quantinuum H-series trapped-ion quantum computers through the NEXUS platform.</p>"},{"location":"providers/quantinuum/#prerequisites","title":"Prerequisites","text":"<ul> <li>A Quantinuum NEXUS account</li> <li>NEXUS credentials (username and password)</li> </ul>"},{"location":"providers/quantinuum/#setup","title":"Setup","text":""},{"location":"providers/quantinuum/#1-get-nexus-credentials","title":"1. Get NEXUS Credentials","text":"<ol> <li>Register at Quantinuum NEXUS</li> <li>Note your username and password</li> </ol>"},{"location":"providers/quantinuum/#2-configure-environment","title":"2. Configure Environment","text":"<p>Add to your <code>.env</code> file:</p> <pre><code>QUANTINUUM_NEXUS_USERNAME=\"&lt;your-username&gt;\"\nQUANTINUUM_NEXUS_PASSWORD=\"&lt;your-password&gt;\"\nQUANTINUUM_NEXUS_PROJECT_NAME=\"metriq-gym\"\n\n# Optional: optimization level for compilation (default: 1)\nQUANTINUUM_NEXUS_OPT_LEVEL=\"1\"\n</code></pre>"},{"location":"providers/quantinuum/#3-initial-login","title":"3. Initial Login","text":"<p>The first time you use Quantinuum, you must complete a manual login workflow:</p> <pre><code>qnx login\n</code></pre> <p>Follow the prompts to authenticate and link your account.</p>"},{"location":"providers/quantinuum/#discovering-devices","title":"Discovering Devices","text":"<p>Quantinuum offers H-series hardware, emulators, and syntax checkers. To see currently available devices:</p> <pre><code>from qbraid.runtime import load_provider\n\nprovider = load_provider(\"quantinuum\")\nfor device in provider.get_devices():\n    print(f\"{device.id}: {device.status}\")\n</code></pre> <p>Or check the NEXUS portal for current device availability.</p> <p>Tip</p> <p>Use syntax checkers (devices ending in <code>SC</code>) to validate circuits before running on hardware. They're free and instant.</p>"},{"location":"providers/quantinuum/#usage","title":"Usage","text":""},{"location":"providers/quantinuum/#dispatch-to-quantinuum-hardware","title":"Dispatch to Quantinuum Hardware","text":"<pre><code>mgym job dispatch metriq_gym/schemas/examples/wit.example.json \\\n    --provider quantinuum --device H1-1\n</code></pre>"},{"location":"providers/quantinuum/#dispatch-to-emulator","title":"Dispatch to Emulator","text":"<pre><code>mgym job dispatch metriq_gym/schemas/examples/wit.example.json \\\n    --provider quantinuum --device H1-1E\n</code></pre>"},{"location":"providers/quantinuum/#poll-results","title":"Poll Results","text":"<pre><code>mgym job poll &lt;JOB_ID&gt;\n</code></pre>"},{"location":"providers/quantinuum/#pricing","title":"Pricing","text":"<p>Quantinuum uses H-series Quantum Credits (HQCs) for billing. See Quantinuum's documentation for current pricing details.</p> <p>Use <code>mgym job estimate</code> to estimate HQCs before running:</p> <pre><code>mgym job estimate config.json --provider quantinuum\n</code></pre>"},{"location":"providers/quantinuum/#nexus-projects","title":"NEXUS Projects","text":"<p>Jobs are organized into NEXUS projects. Set the project name:</p> <pre><code>QUANTINUUM_NEXUS_PROJECT_NAME=\"my-project\"\n</code></pre>"},{"location":"providers/quantinuum/#compilation-optimization","title":"Compilation Optimization","text":"<p>Control TKET compilation optimization:</p> <pre><code># Levels: 0 (none), 1 (default), 2 (aggressive)\nQUANTINUUM_NEXUS_OPT_LEVEL=\"2\"\n</code></pre> <p>Higher levels may reduce gate counts but increase compilation time.</p>"},{"location":"providers/quantinuum/#troubleshooting","title":"Troubleshooting","text":""},{"location":"providers/quantinuum/#login-required","title":"Login Required","text":"<p>If you see authentication errors, re-run:</p> <pre><code>qnx login\n</code></pre>"},{"location":"providers/quantinuum/#hqc-limits","title":"HQC Limits","text":"<p>Check your HQC balance in the NEXUS portal. Jobs exceeding your balance will fail.</p>"},{"location":"providers/quantinuum/#compilation-errors","title":"Compilation Errors","text":"<p>Some circuits may not compile efficiently for trapped-ion hardware. Try: - Reducing circuit depth - Using optimization level 2 - Checking for unsupported operations</p>"},{"location":"uploading/github/","title":"Contributing to metriq-data","text":"<p>Metriq-Gym uploads benchmark results to GitHub via pull requests, enabling community contribution to the metriq-data benchmark database.</p>"},{"location":"uploading/github/#overview","title":"Overview","text":"<p>The upload workflow:</p> <ol> <li>Creates a fork of the target repository (if needed)</li> <li>Creates a new branch with your results</li> <li>Opens a pull request for review</li> <li>Once merged, results appear on metriq.info</li> </ol>"},{"location":"uploading/github/#setup","title":"Setup","text":""},{"location":"uploading/github/#1-create-a-github-token","title":"1. Create a GitHub Token","text":"<p>Create a Personal Access Token at github.com/settings/tokens with repository read/write permissions.</p>"},{"location":"uploading/github/#2-configure-environment","title":"2. Configure Environment","text":"<p>Add to your <code>.env</code> file:</p> <pre><code>GITHUB_TOKEN=\"your-token-here\"\n\n# Optional: customize upload destination\nMGYM_UPLOAD_REPO=\"unitaryfoundation/metriq-data\"\nMGYM_UPLOAD_BASE_BRANCH=\"main\"\nMGYM_UPLOAD_DIR=\"\"\n</code></pre>"},{"location":"uploading/github/#upload-commands","title":"Upload Commands","text":""},{"location":"uploading/github/#single-job","title":"Single Job","text":"<pre><code>mgym job upload &lt;JOB_ID&gt;\n</code></pre>"},{"location":"uploading/github/#full-suite","title":"Full Suite","text":"<pre><code>mgym suite upload &lt;SUITE_ID&gt;\n</code></pre>"},{"location":"uploading/github/#upload-options","title":"Upload Options","text":"Option Environment Variable Default Description <code>--repo</code> <code>MGYM_UPLOAD_REPO</code> <code>unitaryfoundation/metriq-data</code> Target repository <code>--dir</code> <code>MGYM_UPLOAD_DIR</code> <code>metriq-gym/v&lt;version&gt;/&lt;provider&gt;/&lt;device&gt;</code> Directory path"},{"location":"uploading/github/#examples","title":"Examples","text":"<pre><code># Default upload\nmgym job upload abc123\n\n# Custom repository\nmgym job upload abc123 --repo myorg/my-data\n\n# Custom directory\nmgym job upload abc123 --dir results/2025/january\n</code></pre>"},{"location":"uploading/github/#upload-process","title":"Upload Process","text":""},{"location":"uploading/github/#1-fork-creation","title":"1. Fork Creation","text":"<p>If you don't have a fork of the target repository, Metriq-Gym automatically creates one.</p>"},{"location":"uploading/github/#2-branch-creation","title":"2. Branch Creation","text":"<p>A branch named <code>mgym/upload-&lt;job_id&gt;</code> is created with your results.</p>"},{"location":"uploading/github/#3-file-structure","title":"3. File Structure","text":"<p>Results are stored as JSON files:</p> <pre><code>metriq-gym/\n\u2514\u2500\u2500 v0.3/\n    \u2514\u2500\u2500 ibm/\n        \u2514\u2500\u2500 ibm_sherbrooke/\n            \u2514\u2500\u2500 2025-01-15T12:00:00_BSEQ_abc123.json\n</code></pre>"},{"location":"uploading/github/#4-pull-request","title":"4. Pull Request","text":"<p>A PR is opened with: - Title: <code>mgym upload: &lt;benchmark&gt; on &lt;provider&gt;/&lt;device&gt;</code> - Labels: <code>data</code>, <code>source:metriq-gym</code></p>"},{"location":"uploading/github/#result-file-format","title":"Result File Format","text":"<pre><code>[\n  {\n    \"app_version\": \"0.3.1\",\n    \"timestamp\": \"2025-01-15T12:00:00.000000\",\n    \"platform\": {\n      \"provider\": \"ibm\",\n      \"device\": \"ibm_sherbrooke\"\n    },\n    \"job_type\": \"BSEQ\",\n    \"results\": {\n      \"values\": {\n        \"largest_connected_size\": 100,\n        \"fraction_connected\": 0.7874\n      },\n      \"uncertainties\": {\n        \"fraction_connected\": 0.01\n      }\n    },\n    \"params\": {\n      \"benchmark_name\": \"BSEQ\",\n      \"shots\": 1000\n    }\n  }\n]\n</code></pre>"},{"location":"uploading/github/#contribution-workflow","title":"Contribution Workflow","text":""},{"location":"uploading/github/#first-time-contributors","title":"First-Time Contributors","text":"<ol> <li>Your fork is created automatically</li> <li>Review the PR before requesting merge</li> <li>Maintainers review and merge contributions</li> </ol>"},{"location":"uploading/github/#repeat-contributors","title":"Repeat Contributors","text":"<p>Subsequent uploads use your existing fork and create new branches.</p>"},{"location":"uploading/github/#troubleshooting","title":"Troubleshooting","text":""},{"location":"uploading/github/#github-token-not-provided","title":"\"GitHub token not provided\"","text":"<p>Ensure <code>GITHUB_TOKEN</code> is set:</p> <pre><code>export GITHUB_TOKEN=\"your-token\"\n# or add to .env file\n</code></pre>"},{"location":"uploading/github/#fork-creation-failed","title":"Fork Creation Failed","text":"<p>If automatic forking fails: 1. Manually fork unitaryfoundation/metriq-data 2. Retry the upload command</p>"},{"location":"uploading/github/#permission-denied","title":"Permission Denied","text":"<p>Verify your token has repository read/write permissions.</p>"},{"location":"uploading/github/#pr-creation-failed","title":"PR Creation Failed","text":"<p>If PR creation fails, the command returns a compare URL. Open it in your browser to manually create the PR.</p>"},{"location":"uploading/github/#best-practices","title":"Best Practices","text":"<ol> <li>Review before upload: Verify results with <code>mgym job poll --json</code> first</li> <li>Don't upload test runs: Only upload meaningful benchmark results</li> <li>Include metadata: Results automatically include version, timestamp, and configuration</li> <li>One PR per upload: Each upload creates a separate PR for easy review</li> </ol>"},{"location":"uploading/github/#external-contributors","title":"External Contributors","text":"<p>If you're contributing from outside the Unitary Foundation:</p> <ol> <li>Fork <code>unitaryfoundation/metriq-data</code> manually (recommended)</li> <li>Set <code>MGYM_UPLOAD_REPO</code> to your fork</li> <li>Create PRs from your fork to the upstream repository</li> </ol>"},{"location":"uploading/github/#programmatic-upload","title":"Programmatic Upload","text":"<p>Use the Python API for custom upload workflows:</p> <pre><code>from types import SimpleNamespace\nfrom metriq_gym.run import upload_job\nfrom metriq_gym.job_manager import JobManager\n\njob_manager = JobManager()\n\nupload_config = SimpleNamespace(\n    job_id=\"your-job-id\",\n    repo=\"unitaryfoundation/metriq-data\",\n    dir=None,  # use default\n)\n\nupload_job(upload_config, job_manager)\n</code></pre>"}]}